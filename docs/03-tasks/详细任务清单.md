# å­¦ä¹ è®°å½•ç®¡ç†ç³»ç»Ÿ - è¯¦ç»†ä»»åŠ¡æ¸…å•

> **é¡¹ç›®åç§°**: StudyNotesManager
> **å›¢é˜Ÿ**: study-notes-dev
> **åˆ›å»ºæ—¥æœŸ**: 2026-02-08
> **ä»»åŠ¡æ€»æ•°**: 10ä¸ª
> **çŠ¶æ€**: å¾…å¯åŠ¨
>
> **å…³è”æ–‡æ¡£**:
> - [[è®°å½•å­¦ä¹ è¿‡ç¨‹é¡¹ç›®]] - åŠŸèƒ½éœ€æ±‚æ–‡æ¡£
> - [[å­¦ä¹ è®°å½•é¡¹ç›®å¸‚åœºå‰æ™¯åˆ†æ]] - å¸‚åœºåˆ†æ
> - [[ç³»ç»Ÿæ¶æ„è®¾è®¡æ–‡æ¡£]] - æŠ€æœ¯æ¶æ„

---

## ğŸ“‹ ä»»åŠ¡æ¦‚è§ˆ

| # | ä»»åŠ¡åç§° | ä¼˜å…ˆçº§ | é¢„è®¡å·¥æœŸ | æŠ€æœ¯æ ˆ | çŠ¶æ€ |
|---|---------|--------|---------|--------|------|
| 9 | é¡¹ç›®æŠ€æœ¯æ ˆæ­å»ºä¸ç¯å¢ƒé…ç½® | P0 | 2-3å¤© | Python/Next.js/Docker | â¸ å¾…å¯åŠ¨ |
| 8 | æ•°æ®åº“Schemaè®¾è®¡ä¸å®ç° | P0 | 3-5å¤© | PostgreSQL/Alembic | â¸ å¾…å¯åŠ¨ |
| 7 | ç”¨æˆ·è®¤è¯ä¸æˆæƒç³»ç»Ÿ | P0 | 4-6å¤© | FastAPI/JWT | â¸ å¾…å¯åŠ¨ |
| 10 | ç¬”è®°ä¸Šä¼ ä¸OCRè¯†åˆ«æ¨¡å— | P1 | 5-7å¤© | FastAPI/ç™¾åº¦OCR | â¸ å¾…å¯åŠ¨ |
| 5 | AIè„‘å›¾è‡ªåŠ¨ç”ŸæˆåŠŸèƒ½ | P1 | 5-7å¤© | DeepSeek API | â¸ å¾…å¯åŠ¨ |
| 6 | åŸºäºè„‘å›¾çš„çŸ¥è¯†ç‚¹æé—®ç³»ç»Ÿ | P1 | 5-7å¤© | LLM/ChromaDB | â¸ å¾…å¯åŠ¨ |
| 3 | é”™é¢˜åº“ç®¡ç†ä¸æ™ºèƒ½åˆ†æ | P1 | 6-8å¤© | FastAPI/ç®—æ³• | â¸ å¾…å¯åŠ¨ |
| 4 | ç¬”è®°åˆ†äº«ä¸åä½œåŠŸèƒ½ | P2 | 7-10å¤© | WebSocket/Yjs | â¸ å¾…å¯åŠ¨ |
| 2 | å­¦ä¹ æ•°æ®åˆ†æä¸å¯è§†åŒ– | P2 | 5-7å¤© | FastAPI/ECharts | â¸ å¾…å¯åŠ¨ |
| 1 | å‰ç«¯UI/UXå¼€å‘ | P1 | 10-14å¤© | Next.js/React | â¸ å¾…å¯åŠ¨ |

**æ€»é¢„è®¡å·¥æœŸ**: 52-74å¤©ï¼ˆçº¦2-3ä¸ªæœˆï¼‰

---

## #9 é¡¹ç›®æŠ€æœ¯æ ˆæ­å»ºä¸ç¯å¢ƒé…ç½®

**ä¼˜å…ˆçº§**: P0ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
**é¢„è®¡å·¥æœŸ**: 2-3å¤©
**ä¾èµ–**: æ— 
**è´Ÿè´£è§’è‰²**: DevOpså·¥ç¨‹å¸ˆ / åç«¯å·¥ç¨‹å¸ˆ

### ğŸ“Œ ä»»åŠ¡ç›®æ ‡

æ­å»ºé¡¹ç›®åŸºç¡€å¼€å‘ç¯å¢ƒï¼Œä¸ºåç»­å¼€å‘æä¾›ç»Ÿä¸€çš„æŠ€æœ¯åŸºç¡€è®¾æ–½ã€‚

### ğŸ›  æŠ€æœ¯æ ˆ

#### åç«¯
- **è¯­è¨€**: Python 3.11+
- **æ¡†æ¶**: FastAPI 0.104+
- **å¼‚æ­¥**: asyncio + uvloop
- **APIæ–‡æ¡£**: Swagger UI (è‡ªåŠ¨ç”Ÿæˆ)

#### å‰ç«¯
- **æ¡†æ¶**: Next.js 14 (App Router)
- **è¯­è¨€**: TypeScript 5+
- **æ ·å¼**: Tailwind CSS 3.4+
- **ç»„ä»¶åº“**: shadcn/ui
- **çŠ¶æ€ç®¡ç†**: Zustand
- **æ•°æ®è·å–**: React Query

#### æ•°æ®åº“
- **å…³ç³»æ•°æ®åº“**: PostgreSQL 15+
- **å‘é‡æ‰©å±•**: pgvector
- **è¿ç§»å·¥å…·**: Alembic
- **å‘é‡æ•°æ®åº“**: ChromaDB

#### ç¼“å­˜ä¸æ¶ˆæ¯
- **ç¼“å­˜**: Redis 7+
- **æ¶ˆæ¯é˜Ÿåˆ—**: RabbitMQ 3.12+

#### å®¹å™¨åŒ–
- **å®¹å™¨**: Docker 24+
- **ç¼–æ’**: Docker Compose

### ğŸ“ å…·ä½“ä»»åŠ¡æ¸…å•

#### 1. Gitä»“åº“åˆå§‹åŒ–
- [ ] åˆå§‹åŒ–Gitä»“åº“ï¼š`git init`
- [ ] åˆ›å»ºåˆ†æ”¯ç­–ç•¥ï¼šmain/develop/feature/*
- [ ] é…ç½®.gitignoreï¼ˆPython/Node/Docker/IDEï¼‰
- [ ] åˆ›å»ºREADME.mdï¼ˆé¡¹ç›®è¯´æ˜ã€å¿«é€Ÿå¼€å§‹ï¼‰
- [ ] åˆ›å»ºCONTRIBUTING.mdï¼ˆè´¡çŒ®æŒ‡å—ï¼‰
- [ ] é…ç½®GitHub Actions CI/CDï¼ˆå¯é€‰ï¼‰

#### 2. Monorepoç»“æ„åˆ›å»º
```
StudyNotesManager/
â”œâ”€â”€ backend/                # åç«¯é¡¹ç›®
â”‚   â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ alembic/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ pyproject.toml
â”œâ”€â”€ frontend/              # å‰ç«¯é¡¹ç›®
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”œâ”€â”€ docker/                # Dockeré…ç½®
â”‚   â”œâ”€â”€ Dockerfile.backend
â”‚   â”œâ”€â”€ Dockerfile.frontend
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ docs/                  # æ–‡æ¡£
â””â”€â”€ scripts/               # è„šæœ¬
```

#### 3. åç«¯é¡¹ç›®è®¾ç½®
- [ ] åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š`python -m venv venv`
- [ ] å®‰è£…ä¾èµ–ï¼š
  ```bash
  pip install fastapi uvicorn[standard] sqlalchemy psycopg2-binary alembic
  pip install redis aiohttp pydantic pydantic-settings
  pip install python-jose[cryptography] passlib[bcrypt]
  pip install python-multipart
  ```
- [ ] åˆ›å»ºFastAPIåº”ç”¨ç»“æ„ï¼š
  ```
  app/
  â”œâ”€â”€ __init__.py
  â”œâ”€â”€ main.py              # åº”ç”¨å…¥å£
  â”œâ”€â”€ api/                 # APIè·¯ç”±
  â”œâ”€â”€ models/              # SQLAlchemyæ¨¡å‹
  â”œâ”€â”€ schemas/             # Pydanticæ¨¡å¼
  â”œâ”€â”€ services/            # ä¸šåŠ¡é€»è¾‘
  â”œâ”€â”€ core/                # æ ¸å¿ƒé…ç½®
  â””â”€â”€ utils/               # å·¥å…·å‡½æ•°
  ```
- [ ] é…ç½®ç¯å¢ƒå˜é‡ï¼ˆ.env.exampleï¼‰
- [ ] ç¼–å†™åŸºç¡€é…ç½®æ–‡ä»¶ï¼ˆconfig.pyï¼‰

#### 4. å‰ç«¯é¡¹ç›®è®¾ç½®
- [ ] åˆ›å»ºNext.jsé¡¹ç›®ï¼š`npx create-next-app@latest`
- [ ] é…ç½®TypeScriptï¼ˆtsconfig.jsonï¼‰
- [ ] å®‰è£…ä¾èµ–ï¼š
  ```bash
  npm install @tanstack/react-query zustand axios
  npm install -D @types/node
  ```
- [ ] é…ç½®Tailwind CSS
- [ ] å®‰è£…shadcn/uiç»„ä»¶åº“
- [ ] åˆ›å»ºé¡¹ç›®ç»“æ„ï¼š
  ```
  src/
  â”œâ”€â”€ app/                 # Next.js App Router
  â”œâ”€â”€ components/          # Reactç»„ä»¶
  â”œâ”€â”€ lib/                 # å·¥å…·åº“
  â”œâ”€â”€ hooks/               # è‡ªå®šä¹‰Hooks
  â”œâ”€â”€ stores/              # ZustandçŠ¶æ€
  â””â”€â”€ types/               # TypeScriptç±»å‹
  ```

#### 5. Dockeré…ç½®
- [ ] ç¼–å†™Dockerfile.backendï¼š
  ```dockerfile
  FROM python:3.11-slim
  WORKDIR /app
  COPY requirements.txt .
  RUN pip install --no-cache-dir -r requirements.txt
  COPY . .
  CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
  ```
- [ ] ç¼–å†™Dockerfile.frontendï¼š
  ```dockerfile
  FROM node:20-alpine
  WORKDIR /app
  COPY package*.json ./
  RUN npm ci
  COPY . .
  RUN npm run build
  CMD ["npm", "start"]
  ```
- [ ] ç¼–å†™docker-compose.ymlï¼š
  ```yaml
  version: '3.8'
  services:
    postgres:
      image: pgvector/pgvector:pg15
      environment:
        POSTGRES_DB: studynotes
        POSTGRES_USER: user
        POSTGRES_PASSWORD: password
      ports:
        - "5432:5432"
      volumes:
        - postgres_data:/var/lib/postgresql/data

    redis:
      image: redis:7-alpine
      ports:
        - "6379:6379"

    backend:
      build:
        context: ./backend
        dockerfile: ../docker/Dockerfile.backend
      ports:
        - "8000:8000"
      depends_on:
        - postgres
        - redis
      env_file:
        - .env

    frontend:
      build:
        context: ./frontend
        dockerfile: ../docker/Dockerfile.frontend
      ports:
        - "3000:3000"
      depends_on:
        - backend

  volumes:
    postgres_data:
  ```

#### 6. ç¯å¢ƒå˜é‡é…ç½®
åˆ›å»º`.env.example`æ–‡ä»¶ï¼š
```bash
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/studynotes

# Redis
REDIS_URL=redis://localhost:6379/0

# JWT
SECRET_KEY=your-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=15
REFRESH_TOKEN_EXPIRE_DAYS=7

# OCR API
BAIDU_OCR_API_KEY=your-api-key
BAIDU_OCR_SECRET_KEY=your-secret-key

# AI API
DEEPSEEK_API_KEY=your-deepseek-api-key
OPENAI_API_KEY=your-openai-api-key

# OSS
OSS_ACCESS_KEY_ID=your-access-key
OSS_ACCESS_KEY_SECRET=your-secret-key
OSS_BUCKET=study-notes
OSS_ENDPOINT=oss-cn-hangzhou.aliyuncs.com

# CORS
FRONTEND_URL=http://localhost:3000
```

#### 7. ä»£ç è§„èŒƒé…ç½®

**åç«¯ï¼ˆPythonï¼‰**:
- [ ] å®‰è£…Blackï¼ˆä»£ç æ ¼å¼åŒ–ï¼‰ï¼š`pip install black`
- [ ] å®‰è£…ruffï¼ˆlinterï¼‰ï¼š`pip install ruff`
- [ ] é…ç½®pyproject.toml
- [ ] é…ç½®pre-commit hooks

**å‰ç«¯ï¼ˆTypeScriptï¼‰**:
- [ ] é…ç½®ESLintï¼ˆ.eslintrc.jsonï¼‰
- [ ] é…ç½®Prettierï¼ˆ.prettierrcï¼‰
- [ ] é…ç½®VSCode settings.json

### âœ… éªŒæ”¶æ ‡å‡†

- [ ] **Dockerå¯åŠ¨æˆåŠŸ**: `docker-compose up -d`æ— é”™è¯¯å¯åŠ¨æ‰€æœ‰æœåŠ¡
- [ ] **åç«¯å¥åº·æ£€æŸ¥**: è®¿é—®`http://localhost:8000/health`è¿”å›200
- [ ] **å‰ç«¯å¯è®¿é—®**: è®¿é—®`http://localhost:3000`æ˜¾ç¤ºé¦–é¡µ
- [ ] **æ•°æ®åº“è¿æ¥**: åç«¯å¯ä»¥æˆåŠŸè¿æ¥PostgreSQL
- [ ] **Redisè¿æ¥**: åç«¯å¯ä»¥æˆåŠŸè¿æ¥Redis
- [ ] **ä»£ç è§„èŒƒ**: Black/ruff/ESLint/Prettieré…ç½®å®Œæˆ
- [ ] **æ–‡æ¡£å®Œå–„**: README.mdåŒ…å«å®Œæ•´çš„ç¯å¢ƒæ­å»ºæŒ‡å—

### ğŸ”— ç›¸å…³èµ„æº

- FastAPIå®˜æ–¹æ–‡æ¡£: https://fastapi.tiangolo.com/
- Next.jså®˜æ–¹æ–‡æ¡£: https://nextjs.org/docs
- Dockerå®˜æ–¹æ–‡æ¡£: https://docs.docker.com/
- PostgreSQL pgvector: https://github.com/pgvector/pgvector

---

## #8 æ•°æ®åº“Schemaè®¾è®¡ä¸å®ç°

**ä¼˜å…ˆçº§**: P0
**é¢„è®¡å·¥æœŸ**: 3-5å¤©
**ä¾èµ–**: ä»»åŠ¡#9ï¼ˆæŠ€æœ¯æ ˆæ­å»ºï¼‰
**è´Ÿè´£è§’è‰²**: æ•°æ®åº“å·¥ç¨‹å¸ˆ / åç«¯å·¥ç¨‹å¸ˆ

### ğŸ“Œ ä»»åŠ¡ç›®æ ‡

è®¾è®¡å¹¶å®ç°å®Œæ•´çš„æ•°æ®åº“ç»“æ„ï¼Œæ”¯æŒç”¨æˆ·ç®¡ç†ã€ç¬”è®°å­˜å‚¨ã€è„‘å›¾ç”Ÿæˆã€é”™é¢˜ç®¡ç†ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚

### ğŸ“š å‚è€ƒæ–‡æ¡£

- [[ç³»ç»Ÿæ¶æ„è®¾è®¡æ–‡æ¡£]] ç¬¬ä¸‰ç«  - æ•°æ®åº“è®¾è®¡
- PostgreSQL 15å®˜æ–¹æ–‡æ¡£
- pgvectoræ‰©å±•æ–‡æ¡£

### ğŸ—„ æ ¸å¿ƒè¡¨ç»“æ„

#### 1. usersï¼ˆç”¨æˆ·è¡¨ï¼‰
```sql
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    full_name VARCHAR(100),

    -- è®¢é˜…ä¿¡æ¯
    subscription_tier VARCHAR(20) DEFAULT 'free', -- free, pro, team
    subscription_expires_at TIMESTAMP,

    -- OAuthï¼ˆå¯é€‰ï¼‰
    oauth_provider VARCHAR(50),
    oauth_id VARCHAR(255),

    -- è´¦æˆ·çŠ¶æ€
    is_active BOOLEAN DEFAULT true,
    is_verified BOOLEAN DEFAULT false,
    verification_token VARCHAR(255),

    -- æ—¶é—´æˆ³
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    last_login_at TIMESTAMP,

    -- å…ƒæ•°æ®
    metadata JSONB DEFAULT '{}'
);

CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_subscription ON users(subscription_tier);
```

#### 2. notesï¼ˆç¬”è®°è¡¨ï¼‰
```sql
CREATE TABLE notes (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,

    -- ç¬”è®°å†…å®¹
    title VARCHAR(255) NOT NULL,
    content TEXT,                          -- ç¬”è®°æ–‡æœ¬å†…å®¹
    file_type VARCHAR(20) NOT NULL,        -- image, pdf, handwriting, text
    file_url VARCHAR(500),                 -- OSSæ–‡ä»¶è·¯å¾„
    thumbnail_url VARCHAR(500),            -- ç¼©ç•¥å›¾URL

    -- OCRç»“æœ
    ocr_text TEXT,                         -- OCRè¯†åˆ«çš„æ–‡æœ¬
    ocr_confidence DECIMAL(3,2),           -- OCRç½®ä¿¡åº¦

    -- å‘é‡åµŒå…¥
    embedding VECTOR(1536),                -- å†…å®¹å‘é‡ï¼ˆç”¨äºè¯­ä¹‰æœç´¢ï¼‰

    -- åˆ†ç±»
    category_id UUID REFERENCES categories(id),

    -- ç»Ÿè®¡
    view_count INTEGER DEFAULT 0,
    mindmap_count INTEGER DEFAULT 0,

    -- æ—¶é—´æˆ³
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),

    -- å…ƒæ•°æ®
    metadata JSONB DEFAULT '{}'
);

CREATE INDEX idx_notes_user ON notes(user_id, created_at DESC);
CREATE INDEX idx_notes_category ON notes(category_id);
CREATE INDEX idx_notes_embedding ON notes USING ivfflat (embedding vector_cosine_ops)
    WITH (lists = 100);
```

#### 3. mindmapsï¼ˆè„‘å›¾è¡¨ï¼‰
```sql
CREATE TABLE mindmaps (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    note_id UUID REFERENCES notes(id) ON DELETE CASCADE,

    -- è„‘å›¾ç»“æ„
    structure JSONB NOT NULL,              /*
    {
        "id": "root",
        "text": "ä¸­å¿ƒä¸»é¢˜",
        "children": [
            {
                "id": "node1",
                "text": "åˆ†æ”¯1",
                "children": [...]
            }
        ]
    }
    */

    -- è„‘å›¾ç±»å‹
    map_type VARCHAR(20) DEFAULT 'user_generated',
    -- user_generated, ai_generated, textbook_comparison

    -- AIç”Ÿæˆä¿¡æ¯
    ai_model VARCHAR(50),
    ai_generated_at TIMESTAMP,

    -- å¯¹æ¯”åˆ†æï¼ˆå½“map_type=textbook_comparisonæ—¶ï¼‰
    compared_with_mindmap_id UUID REFERENCES mindmaps(id),
    comparison_result JSONB,               -- å·®å¼‚åˆ†æç»“æœ

    -- å…ƒæ•°æ®
    is_template BOOLEAN DEFAULT false,
    is_public BOOLEAN DEFAULT false,
    view_count INTEGER DEFAULT 0,
    fork_count INTEGER DEFAULT 0,

    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_mindmaps_user ON mindmaps(user_id, created_at DESC);
CREATE INDEX idx_mindmaps_note ON mindmaps(note_id);
CREATE INDEX idx_mindmaps_type ON mindmaps(map_type);
CREATE INDEX idx_mindmaps_template ON mindmaps(is_template) WHERE is_template = true;
```

#### 4. mindmap_knowledge_pointsï¼ˆè„‘å›¾çŸ¥è¯†ç‚¹å…³è”è¡¨ï¼‰
```sql
CREATE TABLE mindmap_knowledge_points (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    mindmap_id UUID NOT NULL REFERENCES mindmaps(id) ON DELETE CASCADE,
    node_id VARCHAR(100) NOT NULL,        -- å¯¹åº”structureä¸­çš„èŠ‚ç‚¹ID

    knowledge_text TEXT NOT NULL,
    embedding VECTOR(1536),               -- pgvectorå­˜å‚¨

    -- å…³è”ç¬”è®°å†…å®¹
    related_note_id UUID REFERENCES notes(id),
    related_note_section VARCHAR(100),    -- ç¬”è®°ä¸­çš„ç« èŠ‚/æ®µè½æ ‡è®°

    -- å­¦ä¹ æ•°æ®
    mastery_level DECIMAL(3,2) DEFAULT 0, -- æŒæ¡ç¨‹åº¦ (0-1)
    question_count INTEGER DEFAULT 0,     -- ç›¸å…³é¢˜ç›®æ•°
    mistake_count INTEGER DEFAULT 0,      -- é”™é¢˜æ•°

    created_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(mindmap_id, node_id)
);

CREATE INDEX idx_mindmap_kp_mindmap ON mindmap_knowledge_points(mindmap_id);
CREATE INDEX idx_mindmap_kp_note ON mindmap_knowledge_points(related_note_id);
-- å‘é‡ç›¸ä¼¼åº¦æœç´¢ç´¢å¼•
CREATE INDEX idx_mindmap_kp_embedding ON mindmap_knowledge_points
    USING ivfflat (embedding vector_cosine_ops)
    WITH (lists = 100);
```

#### 5. quiz_questionsï¼ˆæé—®è¡¨ï¼‰
```sql
CREATE TABLE quiz_questions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    knowledge_point_id UUID NOT NULL REFERENCES mindmap_knowledge_points(id) ON DELETE CASCADE,
    note_id UUID REFERENCES notes(id),

    -- é¢˜ç›®å†…å®¹
    question_text TEXT NOT NULL,
    question_type VARCHAR(20) NOT NULL,   -- choice, fill_blank, essay
    options JSONB,                         /*
    é€‰æ‹©é¢˜é€‰é¡¹: ["A. xxx", "B. xxx", "C. xxx", "D. xxx"]
    */

    -- ç­”æ¡ˆ
    correct_answer TEXT NOT NULL,
    answer_explanation TEXT,

    -- å…ƒæ•°æ®
    difficulty VARCHAR(10) DEFAULT 'medium', -- easy, medium, hard
    ai_generated BOOLEAN DEFAULT false,
    ai_model VARCHAR(50),

    -- ç»Ÿè®¡
    attempt_count INTEGER DEFAULT 0,
    correct_count INTEGER DEFAULT 0,

    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_quiz_questions_kp ON quiz_questions(knowledge_point_id);
CREATE INDEX idx_quiz_questions_note ON quiz_questions(note_id);
CREATE INDEX idx_quiz_questions_difficulty ON quiz_questions(difficulty);
```

#### 6. user_quiz_recordsï¼ˆç­”é¢˜è®°å½•è¡¨ï¼‰
```sql
CREATE TABLE user_quiz_records (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    question_id UUID NOT NULL REFERENCES quiz_questions(id) ON DELETE CASCADE,

    -- ç­”é¢˜å†…å®¹
    user_answer TEXT NOT NULL,
    is_correct BOOLEAN NOT NULL,

    -- æ—¶é—´
    answered_at TIMESTAMP DEFAULT NOW(),
    time_spent INTEGER,                   -- ç­”é¢˜ç”¨æ—¶ï¼ˆç§’ï¼‰

    -- é”™é¢˜å®šä½
    related_note_snippet TEXT,            -- ç›¸å…³ç¬”è®°ç‰‡æ®µ
    related_note_section VARCHAR(100),

    UNIQUE(user_id, question_id, answered_at)
);

CREATE INDEX idx_quiz_records_user ON user_quiz_records(user_id, answered_at DESC);
CREATE INDEX idx_quiz_records_question ON user_quiz_records(question_id);
CREATE INDEX idx_quiz_records_correct ON user_quiz_records(user_id, is_correct)
    WHERE is_correct = false;              -- é”™é¢˜ç´¢å¼•
```

#### 7. mistakesï¼ˆé”™é¢˜è¡¨ï¼‰
```sql
CREATE TABLE mistakes (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    question_id UUID REFERENCES quiz_questions(id) ON DELETE CASCADE,

    -- é¢˜ç›®å†…å®¹ï¼ˆå¿«ç…§ï¼Œé˜²æ­¢é¢˜ç›®è¢«ä¿®æ”¹ï¼‰
    question_text TEXT NOT NULL,
    question_type VARCHAR(20) NOT NULL,
    options JSONB,
    correct_answer TEXT NOT NULL,

    -- ç”¨æˆ·é”™è¯¯ç­”æ¡ˆ
    user_answer TEXT NOT NULL,

    -- æ ‡ç­¾ä¸åˆ†ç±»
    tags TEXT[],                          -- ['æ•°å­¦', 'å¾®ç§¯åˆ†', 'å¯¼æ•°']
    category_id UUID REFERENCES categories(id),
    knowledge_point_id UUID REFERENCES mindmap_knowledge_points(id),

    -- ç¬”è®°å…³è”
    related_note_id UUID REFERENCES notes(id),
    related_note_snippet TEXT,

    -- ç»Ÿè®¡
    mistake_count INTEGER DEFAULT 1,      -- é”™è¯¯æ¬¡æ•°
    last_mistake_at TIMESTAMP DEFAULT NOW(),

    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_mistakes_user ON mistakes(user_id, created_at DESC);
CREATE INDEX idx_mistakes_tags ON mistakes USING GIN(tags);
CREATE INDEX idx_mistakes_category ON mistakes(category_id);
CREATE INDEX idx_mistakes_kp ON mistakes(knowledge_point_id);
```

#### 8. mistake_reviewsï¼ˆé”™é¢˜å¤ä¹ è®°å½•ï¼‰
```sql
CREATE TABLE mistake_reviews (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    mistake_id UUID NOT NULL REFERENCES mistakes(id) ON DELETE CASCADE,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,

    -- å¤ä¹ ç»“æœ
    is_correct BOOLEAN NOT NULL,
    review_time INTEGER,                  -- å¤ä¹ ç”¨æ—¶ï¼ˆç§’ï¼‰

    -- è‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿
    review_stage INTEGER DEFAULT 0,       -- 0-6 (7ä¸ªå¤ä¹ é˜¶æ®µ)
    next_review_at TIMESTAMP,             -- ä¸‹æ¬¡å¤ä¹ æ—¶é—´

    reviewed_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_mistake_reviews_mistake ON mistake_reviews(mistake_id, reviewed_at DESC);
CREATE INDEX idx_mistake_reviews_user ON mistake_reviews(user_id, next_review_at)
    WHERE next_review_at IS NOT NULL;     -- å¾…å¤ä¹ ç´¢å¼•
```

#### 9. categoriesï¼ˆåˆ†ç±»è¡¨ï¼‰
```sql
CREATE TABLE categories (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,

    name VARCHAR(100) NOT NULL,
    description TEXT,
    color VARCHAR(7),                     -- åå…­è¿›åˆ¶é¢œè‰²ç 
    icon VARCHAR(50),                     -- å›¾æ ‡åç§°

    -- å±‚çº§ç»“æ„
    parent_id UUID REFERENCES categories(id),
    level INTEGER DEFAULT 0,              -- 0=æ ¹åˆ†ç±», 1=å­åˆ†ç±»...

    -- ç»Ÿè®¡
    notes_count INTEGER DEFAULT 0,
    children_count INTEGER DEFAULT 0,

    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),

    UNIQUE(user_id, name, parent_id)
);

CREATE INDEX idx_categories_user ON categories(user_id, parent_id);
```

#### 10. category_relationsï¼ˆåˆ†ç±»å…³ç³»è¡¨ï¼‰
```sql
CREATE TABLE category_relations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,

    category_a_id UUID NOT NULL REFERENCES categories(id) ON DELETE CASCADE,
    category_b_id UUID NOT NULL REFERENCES categories(id) ON DELETE CASCADE,

    -- å…³ç³»ç±»å‹
    relation_type VARCHAR(20) NOT NULL,   -- related, independent

    -- æƒé‡ï¼ˆç”¨äºè®¡ç®—å…³è”å¼ºåº¦ï¼‰
    weight DECIMAL(3,2) DEFAULT 0.5,

    created_at TIMESTAMP DEFAULT NOW(),

    UNIQUE(category_a_id, category_b_id),
    CHECK (category_a_id < category_b_id)  -- é¿å…é‡å¤å­˜å‚¨ (A,B) å’Œ (B,A)
);

CREATE INDEX idx_category_relations_user ON category_relations(user_id);
CREATE INDEX idx_category_relations_type ON category_relations(relation_type);
```

#### 11. note_sharesï¼ˆç¬”è®°åˆ†äº«è¡¨ï¼‰
```sql
CREATE TABLE note_shares (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    note_id UUID NOT NULL REFERENCES notes(id) ON DELETE CASCADE,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,

    -- åˆ†äº«é…ç½®
    share_id VARCHAR(20) UNIQUE NOT NULL,  -- çŸ­é“¾æ¥ID
    access_type VARCHAR(20) DEFAULT 'public', -- public, password, restricted
    password_hash VARCHAR(255),            -- å¯†ç ä¿æŠ¤çš„å“ˆå¸Œ

    -- æƒé™
    allow_download BOOLEAN DEFAULT true,
    allow_merge BOOLEAN DEFAULT true,

    -- ç»Ÿè®¡
    view_count INTEGER DEFAULT 0,
    download_count INTEGER DEFAULT 0,
    merge_count INTEGER DEFAULT 0,

    -- è¿‡æœŸæ—¶é—´
    expires_at TIMESTAMP,

    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_note_shares_note ON note_shares(note_id);
CREATE INDEX idx_note_shares_user ON note_shares(user_id);
CREATE INDEX idx_note_shares_id ON note_shares(share_id);
CREATE INDEX idx_note_shares_expires ON note_shares(expires_at)
    WHERE expires_at IS NOT NULL;
```

#### 12. study_sessionsï¼ˆå­¦ä¹ ä¼šè¯è®°å½•ï¼‰
```sql
CREATE TABLE study_sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,

    -- ä¼šè¯ä¿¡æ¯
    session_type VARCHAR(20) NOT NULL,    -- note_reading, quiz_practice, mistake_review
    related_note_id UUID REFERENCES notes(id),
    related_quiz_id UUID REFERENCES quiz_questions(id),

    -- æ—¶é•¿
    duration_seconds INTEGER NOT NULL,    -- å­¦ä¹ æ—¶é•¿ï¼ˆç§’ï¼‰

    -- æ•°æ®ç»Ÿè®¡
    questions_answered INTEGER DEFAULT 0,
    questions_correct INTEGER DEFAULT 0,
    notes_created INTEGER DEFAULT 0,

    -- æ—¶é—´
    started_at TIMESTAMP NOT NULL,
    ended_at TIMESTAMP NOT NULL,

    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_study_sessions_user ON study_sessions(user_id, started_at DESC);
CREATE INDEX idx_study_sessions_type ON study_sessions(session_type);
```

### ğŸ”§ æŠ€æœ¯å®ç°

#### 1. ä½¿ç”¨Alembicè¿›è¡Œæ•°æ®åº“è¿ç§»

**å®‰è£…Alembic**:
```bash
pip install alembic
alembic init alembic
```

**é…ç½®alembic.ini**:
```ini
[alembic]
script_location = alembic
sqlalchemy.url = postgresql://user:password@localhost:5432/studynotes
```

**é…ç½®env.py**:
```python
from sqlalchemy import engine_from_config
from app.models import Base  # å¯¼å…¥æ‰€æœ‰æ¨¡å‹

target_metadata = Base.metadata
```

#### 2. åˆ›å»ºè¿ç§»è„šæœ¬
```bash
# ç”Ÿæˆåˆå§‹è¿ç§»
alembic revision --autogenerate -m "Initial schema"

# æ‰§è¡Œè¿ç§»
alembic upgrade head

# å›æ»š
alembic downgrade -1
```

#### 3. åœ¨FastAPIä¸­ä½¿ç”¨SQLAlchemy

**database.py**:
```python
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

DATABASE_URL = "postgresql://user:password@localhost:5432/studynotes"

engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

### âœ… éªŒæ”¶æ ‡å‡†

- [ ] **æ‰€æœ‰è¡¨åˆ›å»ºæˆåŠŸ**: æ‰§è¡Œè¿ç§»è„šæœ¬æ— é”™è¯¯
- [ ] **å¤–é”®å…³ç³»æ­£ç¡®**: çº§è”åˆ é™¤æ­£å¸¸å·¥ä½œ
- [ ] **ç´¢å¼•åˆ›å»ºæˆåŠŸ**: åŒ…æ‹¬å‘é‡ç´¢å¼•
- [ ] **è¿ç§»è„šæœ¬å¯æ‰§è¡Œ**: `alembic upgrade head`æˆåŠŸ
- [ ] **æ•°æ®å®Œæ•´æ€§çº¦æŸ**: CHECKçº¦æŸã€UNIQUEçº¦æŸæ­£å¸¸
- [ ] **æ€§èƒ½æµ‹è¯•**: å‘é‡ç›¸ä¼¼åº¦æŸ¥è¯¢<100ms
- [ ] **æ–‡æ¡£å®Œæ•´**: ERå›¾ã€è¡¨ç»“æ„è¯´æ˜æ–‡æ¡£

### ğŸ”— ç›¸å…³èµ„æº

- PostgreSQLå®˜æ–¹æ–‡æ¡£: https://www.postgresql.org/docs/15/
- pgvector GitHub: https://github.com/pgvector/pgvector
- Alembicæ–‡æ¡£: https://alembic.sqlalchemy.org/

---

## #7 ç”¨æˆ·è®¤è¯ä¸æˆæƒç³»ç»Ÿ

**ä¼˜å…ˆçº§**: P0
**é¢„è®¡å·¥æœŸ**: 4-6å¤©
**ä¾èµ–**: ä»»åŠ¡#8ï¼ˆæ•°æ®åº“Schemaï¼‰
**è´Ÿè´£è§’è‰²**: åç«¯å·¥ç¨‹å¸ˆ

### ğŸ“Œ ä»»åŠ¡ç›®æ ‡

å®ç°å®Œæ•´çš„ç”¨æˆ·è®¤è¯ä¸æˆæƒç³»ç»Ÿï¼ŒåŒ…æ‹¬æ³¨å†Œã€ç™»å½•ã€JWTä»¤ç‰Œç®¡ç†ã€å¯†ç é‡ç½®ã€OAuthç­‰åŠŸèƒ½ã€‚

### ğŸ“ åŠŸèƒ½éœ€æ±‚

#### 1. ç”¨æˆ·æ³¨å†Œ
- é‚®ç®±æ³¨å†Œï¼ˆé‚®ç®±æ ¼å¼éªŒè¯ï¼‰
- å¯†ç å¼ºåº¦éªŒè¯ï¼ˆè‡³å°‘8ä½ï¼ŒåŒ…å«å­—æ¯å’Œæ•°å­—ï¼‰
- æ£€æŸ¥é‚®ç®±æ˜¯å¦å·²å­˜åœ¨
- å‘é€éªŒè¯é‚®ä»¶ï¼ˆå¯é€‰ï¼‰
- å¯†ç ä½¿ç”¨bcryptåŠ å¯†å­˜å‚¨

#### 2. ç”¨æˆ·ç™»å½•
- é‚®ç®±+å¯†ç ç™»å½•
- è¿”å›JWT access tokenå’Œrefresh token
- è®°å½•æœ€åç™»å½•æ—¶é—´
- æ”¯æŒè®°ä½æˆ‘ï¼ˆå»¶é•¿refresh tokenæœ‰æ•ˆæœŸï¼‰

#### 3. JWT Tokenç®¡ç†
- **Access Token**: æœ‰æ•ˆæœŸ15åˆ†é’Ÿ
- **Refresh Token**: æœ‰æ•ˆæœŸ7å¤©
- Tokenåˆ·æ–°æœºåˆ¶
- Tokené»‘åå•ï¼ˆç”¨äºç™»å‡ºï¼‰

#### 4. å¯†ç é‡ç½®
- å¿˜è®°å¯†ç åŠŸèƒ½
- å‘é€é‡ç½®é‚®ä»¶ï¼ˆå«é‡ç½®é“¾æ¥ï¼‰
- éªŒè¯é‡ç½®token
- æ›´æ–°æ–°å¯†ç 

#### 5. é‚®ç®±éªŒè¯
- å‘é€éªŒè¯é‚®ä»¶
- éªŒè¯é‚®ç®±token
- æœªéªŒè¯ç”¨æˆ·é™åˆ¶åŠŸèƒ½

#### 6. OAuthç™»å½•ï¼ˆå¯é€‰ï¼‰
- Google OAuth 2.0
- GitHub OAuth
- ç»‘å®šå·²æœ‰è´¦æˆ·

#### 7. åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶ï¼ˆRBACï¼‰
- **Freeç”¨æˆ·**: 5ä¸ªç¬”è®°ï¼ŒåŸºç¡€åŠŸèƒ½
- **Proç”¨æˆ·**: æ— é™ç¬”è®°ï¼Œè„‘å›¾å¯¹æ¯”ï¼Œæ•°æ®åˆ†æ
- **Teamç”¨æˆ·**: åŒ…å«ProåŠŸèƒ½+å›¢é˜Ÿåä½œ

### ğŸ”Œ APIç«¯ç‚¹è®¾è®¡

#### 1. ç”¨æˆ·æ³¨å†Œ
```
POST /api/auth/register
Content-Type: application/json

Request:
{
  "email": "user@example.com",
  "password": "SecurePass123",
  "full_name": "John Doe"
}

Response 201:
{
  "id": "uuid",
  "email": "user@example.com",
  "full_name": "John Doe",
  "subscription_tier": "free",
  "is_verified": false,
  "access_token": "jwt_token",
  "refresh_token": "jwt_token"
}

Response 400:
{
  "detail": "Email already registered"
}
```

#### 2. ç”¨æˆ·ç™»å½•
```
POST /api/auth/login
Content-Type: application/json

Request:
{
  "email": "user@example.com",
  "password": "SecurePass123"
}

Response 200:
{
  "access_token": "jwt_token",
  "refresh_token": "jwt_token",
  "token_type": "bearer",
  "expires_in": 900  // ç§’
}

Response 401:
{
  "detail": "Incorrect email or password"
}
```

#### 3. Tokenåˆ·æ–°
```
POST /api/auth/refresh-token
Content-Type: application/json

Request:
{
  "refresh_token": "jwt_token"
}

Response 200:
{
  "access_token": "new_jwt_token",
  "refresh_token": "new_jwt_token",
  "token_type": "bearer",
  "expires_in": 900
}

Response 401:
{
  "detail": "Invalid refresh token"
}
```

#### 4. ç”¨æˆ·ç™»å‡º
```
POST /api/auth/logout
Authorization: Bearer {access_token}
Content-Type: application/json

Request:
{
  "refresh_token": "jwt_token"
}

Response 200:
{
  "message": "Successfully logged out"
}
```

#### 5. è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
```
GET /api/auth/me
Authorization: Bearer {access_token}

Response 200:
{
  "id": "uuid",
  "email": "user@example.com",
  "full_name": "John Doe",
  "subscription_tier": "pro",
  "subscription_expires_at": "2026-03-08T00:00:00Z",
  "is_verified": true,
  "created_at": "2026-02-08T00:00:00Z",
  "last_login_at": "2026-02-08T10:30:00Z"
}

Response 401:
{
  "detail": "Not authenticated"
}
```

#### 6. å¿˜è®°å¯†ç 
```
POST /api/auth/forgot-password
Content-Type: application/json

Request:
{
  "email": "user@example.com"
}

Response 200:
{
  "message": "Password reset email sent"
}
```

#### 7. é‡ç½®å¯†ç 
```
POST /api/auth/reset-password
Content-Type: application/json

Request:
{
  "token": "reset_token_from_email",
  "new_password": "NewSecurePass123"
}

Response 200:
{
  "message": "Password reset successfully"
}
```

#### 8. éªŒè¯é‚®ç®±
```
POST /api/auth/verify-email
Content-Type: application/json

Request:
{
  "token": "verification_token_from_email"
}

Response 200:
{
  "message": "Email verified successfully"
}
```

### ğŸ” å®‰å…¨è¦æ±‚

#### 1. å¯†ç å®‰å…¨
- æœ€å°é•¿åº¦ï¼š8ä½
- å¿…é¡»åŒ…å«ï¼šå¤§å†™å­—æ¯ã€å°å†™å­—æ¯ã€æ•°å­—
- å¯é€‰ï¼šç‰¹æ®Šå­—ç¬¦
- ä½¿ç”¨bcryptåŠ å¯†ï¼ˆcost=12ï¼‰

#### 2. JWTå®‰å…¨
- Access Tokenè¿‡æœŸæ—¶é—´ï¼š15åˆ†é’Ÿ
- Refresh Tokenè¿‡æœŸæ—¶é—´ï¼š7å¤©
- ä½¿ç”¨HS256ç®—æ³•
- å¯†é’¥ä»ç¯å¢ƒå˜é‡è¯»å–ï¼ˆè‡³å°‘32å­—ç¬¦ï¼‰
- Tokenå­˜å‚¨åœ¨HttpOnly Cookieï¼ˆå¯é€‰ï¼‰

#### 3. Rate Limiting
é˜²æ­¢æš´åŠ›ç ´è§£ï¼š
- ç™»å½•ï¼šæ¯IPæ¯åˆ†é’Ÿæœ€å¤š5æ¬¡
- æ³¨å†Œï¼šæ¯IPæ¯åˆ†é’Ÿæœ€å¤š3æ¬¡
- å¯†ç é‡ç½®ï¼šæ¯IPæ¯åˆ†é’Ÿæœ€å¤š2æ¬¡

ä½¿ç”¨slowapiåº“å®ç°ï¼š
```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.post("/api/auth/login")
@limiter.limit("5/minute")
async def login(request: Request):
    ...
```

#### 4. HTTPS Only
- ç”Ÿäº§ç¯å¢ƒå¼ºåˆ¶HTTPS
- Cookieè®¾ç½®Secureæ ‡å¿—
- CORSé…ç½®ä¸¥æ ¼é™åˆ¶æ¥æº

#### 5. è¾“å…¥éªŒè¯
ä½¿ç”¨Pydanticæ¨¡å‹éªŒè¯ï¼š
```python
from pydantic import BaseModel, EmailStr, Field, validator

class UserRegister(BaseModel):
    email: EmailStr
    password: str = Field(..., min_length=8, max_length=100)
    full_name: str = Field(..., min_length=2, max_length=100)

    @validator('password')
    def validate_password(cls, v):
        if not any(c.isupper() for c in v):
            raise ValueError('Password must contain uppercase letter')
        if not any(c.islower() for c in v):
            raise ValueError('Password must contain lowercase letter')
        if not any(c.isdigit() for c in v):
            raise ValueError('Password must contain digit')
        return v
```

### ğŸ’» ä»£ç å®ç°

#### 1. JWTå·¥å…·å‡½æ•°
```python
# app/utils/jwt.py
from datetime import datetime, timedelta
from jose import JWTError, jwt
from app.core.config import settings

def create_access_token(data: dict):
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(minutes=15)
    to_encode.update({"exp": expire, "type": "access"})
    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)
    return encoded_jwt

def create_refresh_token(data: dict):
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(days=7)
    to_encode.update({"exp": expire, "type": "refresh"})
    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)
    return encoded_jwt

def verify_token(token: str):
    try:
        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])
        return payload
    except JWTError:
        return None
```

#### 2. è®¤è¯ä¾èµ–
```python
# app/api/dependencies.py
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from app.utils.jwt import verify_token

security = HTTPBearer()

async def get_current_user(
    credentials: HTTPAuthorizationCredentials = Depends(security),
    db: Session = Depends(get_db)
):
    token = credentials.credentials
    payload = verify_token(token)

    if payload is None or payload.get("type") != "access":
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid authentication credentials"
        )

    user_id = payload.get("sub")
    user = db.query(User).filter(User.id == user_id).first()

    if user is None:
        raise HTTPException(status_code=404, detail="User not found")

    return user
```

#### 3. è®¤è¯è·¯ç”±
```python
# app/api/auth.py
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.security import OAuth2PasswordRequestForm
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.models.user import User
from app.schemas.auth import UserRegister, UserLogin, Token
from app.utils.jwt import create_access_token, create_refresh_token
from app.utils.security import verify_password, hash_password

router = APIRouter(prefix="/api/auth", tags=["auth"])

@router.post("/register", response_model=Token, status_code=status.HTTP_201_CREATED)
async def register(user_data: UserRegister, db: Session = Depends(get_db)):
    # æ£€æŸ¥é‚®ç®±æ˜¯å¦å·²å­˜åœ¨
    existing_user = db.query(User).filter(User.email == user_data.email).first()
    if existing_user:
        raise HTTPException(status_code=400, detail="Email already registered")

    # åˆ›å»ºæ–°ç”¨æˆ·
    hashed_password = hash_password(user_data.password)
    new_user = User(
        email=user_data.email,
        password_hash=hashed_password,
        full_name=user_data.full_name
    )
    db.add(new_user)
    db.commit()
    db.refresh(new_user)

    # ç”Ÿæˆtoken
    access_token = create_access_token({"sub": str(new_user.id)})
    refresh_token = create_refresh_token({"sub": str(new_user.id)})

    return Token(
        access_token=access_token,
        refresh_token=refresh_token,
        token_type="bearer"
    )

@router.post("/login", response_model=Token)
async def login(
    form_data: OAuth2PasswordRequestForm = Depends(),
    db: Session = Depends(get_db)
):
    # æŸ¥æ‰¾ç”¨æˆ·
    user = db.query(User).filter(User.email == form_data.username).first()
    if not user or not verify_password(form_data.password, user.password_hash):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect email or password"
        )

    # æ›´æ–°æœ€åç™»å½•æ—¶é—´
    user.last_login_at = datetime.utcnow()
    db.commit()

    # ç”Ÿæˆtoken
    access_token = create_access_token({"sub": str(user.id)})
    refresh_token = create_refresh_token({"sub": str(user.id)})

    return Token(
        access_token=access_token,
        refresh_token=refresh_token,
        token_type="bearer"
    )

@router.post("/refresh-token", response_model=Token)
async def refresh_token(refresh_token: str, db: Session = Depends(get_db)):
    payload = verify_token(refresh_token)
    if payload is None or payload.get("type") != "refresh":
        raise HTTPException(status_code=401, detail="Invalid refresh token")

    user_id = payload.get("sub")
    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")

    # ç”Ÿæˆæ–°token
    access_token = create_access_token({"sub": str(user.id)})
    new_refresh_token = create_refresh_token({"sub": str(user.id)})

    return Token(
        access_token=access_token,
        refresh_token=new_refresh_token,
        token_type="bearer"
    )
```

### âœ… éªŒæ”¶æ ‡å‡†

- [ ] **ç”¨æˆ·æ³¨å†ŒæˆåŠŸ**: é‚®ç®±+å¯†ç æ³¨å†Œï¼Œè¿”å›JWT token
- [ ] **ç”¨æˆ·ç™»å½•æˆåŠŸ**: æ­£ç¡®çš„å‡­è¯è¿”å›token
- [ ] **Tokenè‡ªåŠ¨åˆ·æ–°**: Access tokenè¿‡æœŸåå¯ç”¨refresh tokenåˆ·æ–°
- [ ] **å—ä¿æŠ¤è·¯ç”±éœ€è¦è®¤è¯**: æœªç™»å½•ç”¨æˆ·æ— æ³•è®¿é—®
- [ ] **å¯†ç æ­£ç¡®åŠ å¯†**: æ•°æ®åº“ä¸­å­˜å‚¨bcrypt hash
- [ ] **Rate Limitingç”Ÿæ•ˆ**: è¶…è¿‡é™åˆ¶è¿”å›429é”™è¯¯
- [ ] **è¾“å…¥éªŒè¯**: æ— æ•ˆé‚®ç®±ã€å¼±å¯†ç è¢«æ‹’ç»
- [ ] **ç™»å‡ºåŠŸèƒ½**: TokenåŠ å…¥é»‘åå•ï¼ˆå¯é€‰ï¼‰

### ğŸ”— ç›¸å…³èµ„æº

- FastAPI Security: https://fastapi.tiangolo.com/tutorial/security/
- python-jose: https://python-jose.readthedocs.io/
- passlib: https://passlib.readthedocs.io/
- slowapi: https://slowapi.readthedocs.io/

---

## #10 ç¬”è®°ä¸Šä¼ ä¸OCRè¯†åˆ«æ¨¡å—

**ä¼˜å…ˆçº§**: P1
**é¢„è®¡å·¥æœŸ**: 5-7å¤©
**ä¾èµ–**: ä»»åŠ¡#7ï¼ˆç”¨æˆ·è®¤è¯ï¼‰ã€ä»»åŠ¡#8ï¼ˆæ•°æ®åº“ï¼‰
**è´Ÿè´£è§’è‰²**: åç«¯å·¥ç¨‹å¸ˆ

### ğŸ“Œ ä»»åŠ¡ç›®æ ‡

å®ç°å¤šæ ¼å¼ç¬”è®°ä¸Šä¼ åŠŸèƒ½ï¼Œæ”¯æŒå›¾ç‰‡ã€PDFã€æ‰‹å†™ç¬”è®°ï¼Œé›†æˆOCRè¯†åˆ«æ–‡å­—ï¼Œå¹¶å°†è¯†åˆ«ç»“æœå­˜å‚¨åˆ°æ•°æ®åº“ã€‚

### ğŸ“ åŠŸèƒ½éœ€æ±‚

#### 1. æ–‡ä»¶ä¸Šä¼ 
- æ”¯æŒæ ¼å¼ï¼šJPGã€PNGã€HEICã€PDF
- æ–‡ä»¶å¤§å°é™åˆ¶ï¼šæœ€å¤§50MB
- æ ¼å¼éªŒè¯ï¼ˆMIME typeæ£€æŸ¥ï¼‰
- ç—…æ¯’æ‰«æï¼ˆå¯é€‰ï¼‰
- ç”Ÿæˆç¼©ç•¥å›¾ï¼ˆå›¾ç‰‡ï¼‰

#### 2. OCRè¯†åˆ«
- é›†æˆç™¾åº¦OCR API
- æ”¯æŒå°åˆ·ä½“è¯†åˆ«
- æ”¯æŒæ‰‹å†™ä½“è¯†åˆ«ï¼ˆå¯é€‰ï¼‰
- è¿”å›è¯†åˆ«æ–‡æœ¬å’Œç½®ä¿¡åº¦
- å¤„ç†è¯†åˆ«å¤±è´¥ï¼ˆé™çº§ç­–ç•¥ï¼‰

#### 3. æ–‡ä»¶å­˜å‚¨
- ä¸Šä¼ åˆ°é˜¿é‡Œäº‘OSS
- è¿”å›æ–‡ä»¶URL
- ç¼©ç•¥å›¾å•ç‹¬å­˜å‚¨
- è®¾ç½®è®¿é—®æƒé™ï¼ˆç§æœ‰/å…¬å¼€ï¼‰

#### 4. å‘é‡åŒ–
- è°ƒç”¨Embedding APIï¼ˆOpenAI/DeepSeekï¼‰
- ç”Ÿæˆ1536ç»´å‘é‡
- å­˜å‚¨åˆ°PostgreSQL pgvectorå­—æ®µ

#### 5. ç¬”è®°ç®¡ç†
- åˆ›å»ºç¬”è®°
- æŸ¥çœ‹ç¬”è®°åˆ—è¡¨
- æŸ¥çœ‹ç¬”è®°è¯¦æƒ…
- åˆ é™¤ç¬”è®°
- æ›´æ–°ç¬”è®°å…ƒæ•°æ®

### ğŸ”Œ APIç«¯ç‚¹è®¾è®¡

#### 1. ä¸Šä¼ ç¬”è®°
```
POST /api/notes/upload
Authorization: Bearer {access_token}
Content-Type: multipart/form-data

Request:
{
  "file": <binary>,
  "title": "å¾®ç§¯åˆ†ç¬”è®°ç¬¬ä¸€ç« ",
  "category_id": "uuid"  // å¯é€‰
}

Progress: 0% -> 100%

Response 201:
{
  "id": "uuid",
  "title": "å¾®ç§¯åˆ†ç¬”è®°ç¬¬ä¸€ç« ",
  "file_type": "image",
  "file_url": "https://oss.example.com/notes/xxx.jpg",
  "thumbnail_url": "https://oss.example.com/notes/thumbnails/xxx.jpg",
  "ocr_text": "è¯†åˆ«çš„æ–‡æœ¬å†…å®¹...",
  "ocr_confidence": 0.95,
  "created_at": "2026-02-08T10:30:00Z"
}

Response 400:
{
  "detail": "Invalid file type. Only JPG, PNG, HEIC, PDF are allowed"
}

Response 413:
{
  "detail": "File too large. Maximum size is 50MB"
}
```

#### 2. è·å–ç¬”è®°åˆ—è¡¨
```
GET /api/notes?page=1&limit=20&category_id=uuid&search=å¾®ç§¯åˆ†
Authorization: Bearer {access_token}

Response 200:
{
  "total": 45,
  "page": 1,
  "limit": 20,
  "notes": [
    {
      "id": "uuid",
      "title": "å¾®ç§¯åˆ†ç¬”è®°ç¬¬ä¸€ç« ",
      "file_type": "image",
      "thumbnail_url": "https://oss.example.com/notes/thumbnails/xxx.jpg",
      "category": {
        "id": "uuid",
        "name": "æ•°å­¦"
      },
      "view_count": 12,
      "created_at": "2026-02-08T10:30:00Z"
    }
  ]
}
```

#### 3. è·å–ç¬”è®°è¯¦æƒ…
```
GET /api/notes/{note_id}
Authorization: Bearer {access_token}

Response 200:
{
  "id": "uuid",
  "user_id": "uuid",
  "title": "å¾®ç§¯åˆ†ç¬”è®°ç¬¬ä¸€ç« ",
  "content": null,
  "file_type": "image",
  "file_url": "https://oss.example.com/notes/xxx.jpg",
  "thumbnail_url": "https://oss.example.com/notes/thumbnails/xxx.jpg",
  "ocr_text": "è¯†åˆ«çš„æ–‡æœ¬å†…å®¹...",
  "ocr_confidence": 0.95,
  "category": {
    "id": "uuid",
    "name": "æ•°å­¦"
  },
  "view_count": 13,
  "mindmap_count": 1,
  "created_at": "2026-02-08T10:30:00Z",
  "updated_at": "2026-02-08T10:30:00Z"
}

Response 404:
{
  "detail": "Note not found"
}
```

#### 4. åˆ é™¤ç¬”è®°
```
DELETE /api/notes/{note_id}
Authorization: Bearer {access_token}

Response 204:
// No content

Response 403:
{
  "detail": "You don't have permission to delete this note"
}

Response 404:
{
  "detail": "Note not found"
}
```

#### 5. æ›´æ–°ç¬”è®°
```
PUT /api/notes/{note_id}
Authorization: Bearer {access_token}
Content-Type: application/json

Request:
{
  "title": "å¾®ç§¯åˆ†ç¬”è®°ç¬¬ä¸€ç« ï¼ˆä¿®è®¢ç‰ˆï¼‰",
  "category_id": "uuid"
}

Response 200:
{
  "id": "uuid",
  "title": "å¾®ç§¯åˆ†ç¬”è®°ç¬¬ä¸€ç« ï¼ˆä¿®è®¢ç‰ˆï¼‰",
  "updated_at": "2026-02-08T11:00:00Z"
}
```

### ğŸ’» æŠ€æœ¯å®ç°

#### 1. æ–‡ä»¶ä¸Šä¼ å¤„ç†
```python
# app/services/file_upload.py
from fastapi import UploadFile, HTTPException
from pathlib import Path
import aiofiles
import aiohttp
from app.core.config import settings
from app.services.ocr import BaiduOCR
from app.services.embedding import generate_embedding

ALLOWED_EXTENSIONS = {".jpg", ".jpeg", ".png", ".heic", ".pdf"}
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB

async def upload_note(
    file: UploadFile,
    user_id: str,
    title: str,
    db: Session,
    category_id: str = None
):
    # 1. éªŒè¯æ–‡ä»¶
    await validate_file(file)

    # 2. è¯»å–æ–‡ä»¶å†…å®¹
    file_content = await file.read()

    # 3. ä¸Šä¼ åˆ°OSS
    file_url = await upload_to_oss(file_content, file.filename)

    # 4. ç”Ÿæˆç¼©ç•¥å›¾ï¼ˆå›¾ç‰‡ï¼‰
    thumbnail_url = None
    if file.content_type.startswith("image/"):
        thumbnail_url = await generate_thumbnail(file_content)

    # 5. OCRè¯†åˆ«
    ocr_result = await BaiduOCR.recognize(file_content, file.content_type)
    ocr_text = ocr_result["text"]
    ocr_confidence = ocr_result["confidence"]

    # 6. å‘é‡åŒ–
    embedding = await generate_embedding(ocr_text)

    # 7. ä¿å­˜åˆ°æ•°æ®åº“
    note = Note(
        user_id=user_id,
        title=title,
        file_type=file.content_type,
        file_url=file_url,
        thumbnail_url=thumbnail_url,
        ocr_text=ocr_text,
        ocr_confidence=ocr_confidence,
        embedding=embedding,
        category_id=category_id
    )
    db.add(note)
    db.commit()
    db.refresh(note)

    return note

async def validate_file(file: UploadFile):
    """éªŒè¯æ–‡ä»¶æ ¼å¼å’Œå¤§å°"""
    # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
    ext = Path(file.filename).suffix.lower()
    if ext not in ALLOWED_EXTENSIONS:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid file type. Only {', '.join(ALLOWED_EXTENSIONS)} are allowed"
        )

    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    content = await file.read()
    file.file.seek(0)  # é‡ç½®æŒ‡é’ˆ
    if len(content) > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=413,
            detail=f"File too large. Maximum size is {MAX_FILE_SIZE / 1024 / 1024}MB"
    )
```

#### 2. ç™¾åº¦OCRé›†æˆ
```python
# app/services/ocr.py
import aiohttp
import base64
from app.core.config import settings

class BaiduOCR:
    API_URL = "https://aip.baidubce.com/rest/2.0/ocr/v1/general_basic"

    @staticmethod
    async def get_access_token():
        """è·å–ç™¾åº¦API access_token"""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://aip.baidubce.com/oauth/2.0/token",
                params={
                    "grant_type": "client_credentials",
                    "client_id": settings.BAIDU_OCR_API_KEY,
                    "client_secret": settings.BAIDU_OCR_SECRET_KEY
                }
            ) as resp:
                data = await resp.json()
                return data["access_token"]

    @staticmethod
    async def recognize(file_content: bytes, content_type: str):
        """OCRè¯†åˆ«"""
        # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡
        if not content_type.startswith("image/"):
            return {"text": "", "confidence": 0}

        # Base64ç¼–ç 
        base64_image = base64.b64encode(file_content).decode("utf-8")

        # è·å–access_token
        access_token = await BaiduOCR.get_access_token()

        # è°ƒç”¨API
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{BaiduOCR.API_URL}?access_token={access_token}",
                data={"image": base64_image}
            ) as resp:
                result = await resp.json()

                if "words_result" not in result:
                    return {"text": "", "confidence": 0}

                # æå–æ–‡æœ¬
                text_lines = [line["words"] for line in result["words_result"]]
                text = "\n".join(text_lines)

                # ç½®ä¿¡åº¦ï¼ˆç™¾åº¦OCRä¸ç›´æ¥æä¾›ï¼Œä½¿ç”¨è¯†åˆ«ç‡ä¼°ç®—ï¼‰
                confidence = min(len(text_lines) / 10, 1.0)

                return {"text": text, "confidence": confidence}
```

#### 3. é˜¿é‡Œäº‘OSSä¸Šä¼ 
```python
# app/services/oss.py
import oss2
from io import BytesIO
from app.core.config import settings

auth = oss2.Auth(settings.OSS_ACCESS_KEY_ID, settings.OSS_ACCESS_KEY_SECRET)
bucket = oss2.Bucket(auth, settings.OSS_ENDPOINT, settings.OSS_BUCKET)

async def upload_to_oss(file_content: bytes, filename: str):
    """ä¸Šä¼ æ–‡ä»¶åˆ°OSS"""
    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    import uuid
    ext = Path(filename).suffix
    object_name = f"notes/{uuid.uuid4()}{ext}"

    # ä¸Šä¼ 
    bucket.put_object(object_name, file_content)

    # è¿”å›URL
    file_url = f"https://{settings.OSS_BUCKET}.{settings.OSS_ENDPOINT}/{object_name}"
    return file_url

async def generate_thumbnail(file_content: bytes):
    """ç”Ÿæˆç¼©ç•¥å›¾"""
    from PIL import Image
    import io

    # æ‰“å¼€å›¾ç‰‡
    img = Image.open(io.BytesIO(file_content))

    # ç¼©æ”¾åˆ°300x300
    img.thumbnail((300, 300))

    # ä¿å­˜åˆ°BytesIO
    thumb_io = io.BytesIO()
    img.save(thumb_io, format="JPEG")
    thumb_content = thumb_io.getvalue()

    # ä¸Šä¼ åˆ°OSS
    return await upload_to_oss(thumb_content, "thumbnail.jpg")
```

#### 4. å‘é‡åŒ–æœåŠ¡
```python
# app/services/embedding.py
import aiohttp
from app.core.config import settings

async def generate_embedding(text: str):
    """ç”Ÿæˆæ–‡æœ¬å‘é‡"""
    async with aiohttp.ClientSession() as session:
        async with session.post(
            "https://api.openai.com/v1/embeddings",
            headers={
                "Authorization": f"Bearer {settings.OPENAI_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "text-embedding-3-small",
                "input": text[:8191]  # OpenAIé™åˆ¶
            }
        ) as resp:
            result = await resp.json()
            embedding = result["data"][0]["embedding"]
            return embedding
```

### âœ… éªŒæ”¶æ ‡å‡†

- [ ] **æ–‡ä»¶ä¸Šä¼ æˆåŠŸ**: æ”¯æŒJPG/PNG/HEIC/PDFæ ¼å¼
- [ ] **æ–‡ä»¶å¤§å°é™åˆ¶**: è¶…è¿‡50MBè¢«æ‹’ç»
- [ ] **OCRè¯†åˆ«å‡†ç¡®**: æ¸…æ™°å›¾ç‰‡è¯†åˆ«å‡†ç¡®ç‡>90%
- [ ] **OCRç»“æœå­˜å‚¨**: æ­£ç¡®ä¿å­˜åˆ°æ•°æ®åº“ocr_textå­—æ®µ
- [ ] **OSSä¸Šä¼ æˆåŠŸ**: æ–‡ä»¶æˆåŠŸä¸Šä¼ åˆ°é˜¿é‡Œäº‘OSS
- [ ] **ç¼©ç•¥å›¾ç”Ÿæˆ**: å›¾ç‰‡è‡ªåŠ¨ç”Ÿæˆç¼©ç•¥å›¾
- [ ] **å‘é‡åŒ–æˆåŠŸ**: ç”Ÿæˆ1536ç»´å‘é‡å­˜å‚¨
- [ ] **è¿”å›æ­£ç¡®URL**: file_urlå’Œthumbnail_urlå¯è®¿é—®

### ğŸ”— ç›¸å…³èµ„æº

- ç™¾åº¦OCR API: https://cloud.baidu.com/product/ocr
- é˜¿é‡Œäº‘OSS Python SDK: https://help.aliyun.com/document_detail/32026.html
- FastAPI File Uploads: https://fastapi.tiangolo.com/tutorial/request-files/

---

## #5 AIè„‘å›¾è‡ªåŠ¨ç”ŸæˆåŠŸèƒ½

**ä¼˜å…ˆçº§**: P1
**é¢„è®¡å·¥æœŸ**: 5-7å¤©
**ä¾èµ–**: ä»»åŠ¡#10ï¼ˆç¬”è®°ä¸Šä¼ ï¼‰
**è´Ÿè´£è§’è‰²**: åç«¯å·¥ç¨‹å¸ˆ + AIå·¥ç¨‹å¸ˆ

### ğŸ“Œ ä»»åŠ¡ç›®æ ‡

åŸºäºç¬”è®°å†…å®¹ï¼Œä½¿ç”¨AIæ¨¡å‹è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–çš„æ€ç»´å¯¼å›¾ï¼Œæ”¯æŒå¤šçº§å±‚çº§ã€ç‰ˆæœ¬æ§åˆ¶ã€‚

### ğŸ“ åŠŸèƒ½éœ€æ±‚

#### 1. è„‘å›¾ç”Ÿæˆ
- è°ƒç”¨DeepSeek/é€šä¹‰åƒé—®API
- ä»ç¬”è®°å†…å®¹æå–çŸ¥è¯†ç‚¹
- æ„å»ºå±‚çº§ç»“æ„ï¼ˆæœ€å¤š5çº§ï¼‰
- è¿”å›æ ‡å‡†JSONæ ¼å¼

#### 2. è„‘å›¾å­˜å‚¨
- ä¿å­˜JSONç»“æ„åˆ°æ•°æ®åº“
- æ”¯æŒç‰ˆæœ¬æ§åˆ¶
- ä¿å­˜AIæ¨¡å‹ä¿¡æ¯

#### 3. è„‘å›¾ç¼–è¾‘
- ç”¨æˆ·æ‰‹åŠ¨ç¼–è¾‘è„‘å›¾
- ä¿å­˜æ–°ç‰ˆæœ¬
- ç‰ˆæœ¬å†å²æŸ¥çœ‹

#### 4. æˆæœ¬æ§åˆ¶
- Tokenä½¿ç”¨é™åˆ¶ï¼ˆæ¯ç¬”è®°2000 tokensï¼‰
- ç”Ÿæˆå¤±è´¥é™çº§ç­–ç•¥
- ç¼“å­˜æœºåˆ¶ï¼ˆ24å°æ—¶ï¼‰

### ğŸ”Œ APIç«¯ç‚¹è®¾è®¡

#### 1. ç”Ÿæˆè„‘å›¾
```
POST /api/mindmaps/generate/{note_id}
Authorization: Bearer {access_token}

Response 202:
{
  "task_id": "uuid",
  "status": "processing",
  "message": "Mindmap generation started"
}

// å¼‚æ­¥å¤„ç†ï¼Œå®Œæˆåé€šè¿‡WebSocketé€šçŸ¥
```

#### 2. è·å–è„‘å›¾
```
GET /api/mindmaps/{mindmap_id}
Authorization: Bearer {access_token}

Response 200:
{
  "id": "uuid",
  "note_id": "uuid",
  "structure": {
    "id": "root",
    "text": "å¾®ç§¯åˆ†åŸºç¡€",
    "children": [
      {
        "id": "node1",
        "text": "å¯¼æ•°",
        "children": [
          {
            "id": "node1-1",
            "text": "å®šä¹‰",
            "children": []
          },
          {
            "id": "node1-2",
            "text": "æ±‚å¯¼æ³•åˆ™",
            "children": []
          }
        ]
      }
    ]
  },
  "map_type": "ai_generated",
  "ai_model": "deepseek-chat",
  "ai_generated_at": "2026-02-08T10:30:00Z",
  "version": 1,
  "is_public": false
}
```

#### 3. æ›´æ–°è„‘å›¾
```
PUT /api/mindmaps/{mindmap_id}
Authorization: Bearer {access_token}
Content-Type: application/json

Request:
{
  "structure": { /* æ–°çš„è„‘å›¾ç»“æ„ */ }
}

Response 200:
{
  "id": "uuid",
  "structure": { /* æ›´æ–°åçš„ç»“æ„ */ },
  "version": 2,
  "updated_at": "2026-02-08T11:00:00Z"
}
```

#### 4. åˆ é™¤è„‘å›¾
```
DELETE /api/mindmaps/{mindmap_id}
Authorization: Bearer {access_token}

Response 204
```

#### 5. è·å–ç‰ˆæœ¬å†å²
```
GET /api/mindmaps/{mindmap_id}/versions
Authorization: Bearer {access_token}

Response 200:
{
  "versions": [
    {
      "version": 1,
      "created_at": "2026-02-08T10:30:00Z",
      "created_by": "ai"
    },
    {
      "version": 2,
      "created_at": "2026-02-08T11:00:00Z",
      "created_by": "user"
    }
  ]
}
```

### ğŸ’» æŠ€æœ¯å®ç°

#### 1. AI Promptè®¾è®¡
```python
# app/prompts/mindmap.py
MINDMAP_GENERATION_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†æ•´ç†åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ç¬”è®°å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„æ€ç»´å¯¼å›¾ã€‚

è¦æ±‚ï¼š
1. æå–æ ¸å¿ƒä¸»é¢˜ä½œä¸ºæ ¹èŠ‚ç‚¹
2. è¯†åˆ«ä¸»è¦åˆ†æ”¯ï¼ˆ2-4ä¸ªï¼‰
3. æ¯ä¸ªåˆ†æ”¯ä¸‹çš„å­èŠ‚ç‚¹ï¼ˆ2-5ä¸ªï¼‰
4. æœ€å¤šæ”¯æŒ5çº§å±‚çº§
5. ä½¿ç”¨ç®€æ´çš„çŸ­è¯­ä½œä¸ºèŠ‚ç‚¹æ–‡æœ¬ï¼ˆä¸è¶…è¿‡10ä¸ªå­—ï¼‰
6. è¿”å›JSONæ ¼å¼

JSONæ ¼å¼ç¤ºä¾‹ï¼š
{
  "id": "root",
  "text": "ä¸­å¿ƒä¸»é¢˜",
  "children": [
    {
      "id": "node1",
      "text": "åˆ†æ”¯1",
      "children": [
        {
          "id": "node1-1",
          "text": "å­èŠ‚ç‚¹1",
          "children": []
        }
      ]
    }
  ]
}

ç¬”è®°å†…å®¹ï¼š
{note_content}

è¯·ç”Ÿæˆè„‘å›¾JSONï¼ˆåªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼‰ï¼š"""
```

#### 2. è„‘å›¾ç”ŸæˆæœåŠ¡
```python
# app/services/mindmap_generator.py
import asyncio
from openai import AsyncOpenAI
from app.core.config import settings
from app.prompts.mindmap import MINDMAP_GENERATION_PROMPT
import json

client = AsyncOpenAI(
    api_key=settings.DEEPSEEK_API_KEY,
    base_url="https://api.deepseek.com"
)

async def generate_mindmap(note_content: str, note_id: str):
    """ç”Ÿæˆè„‘å›¾"""
    # 1. æ£€æŸ¥ç¼“å­˜
    cached = await check_cache(note_id)
    if cached:
        return cached

    # 2. é™åˆ¶è¾“å…¥é•¿åº¦
    truncated_content = note_content[:2000]

    # 3. æ„å»ºprompt
    prompt = MINDMAP_GENERATION_PROMPT.format(note_content=truncated_content)

    # 4. è°ƒç”¨AI
    try:
        response = await client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†æ•´ç†åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,  # é™ä½éšæœºæ€§
            max_tokens=2000
        )

        result = response.choices[0].message.content

        # 5. è§£æJSON
        # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
        result = result.strip()
        if result.startswith("```json"):
            result = result[7:]
        if result.startswith("```"):
            result = result[3:]
        if result.endswith("```"):
            result = result[:-3]

        mindmap_structure = json.loads(result)

        # 6. éªŒè¯ç»“æ„
        validate_mindmap_structure(mindmap_structure)

        # 7. ç¼“å­˜ç»“æœ
        await cache_result(note_id, mindmap_structure)

        return mindmap_structure

    except json.JSONDecodeError as e:
        # JSONè§£æå¤±è´¥ï¼Œå°è¯•é™çº§ç­–ç•¥
        return await fallback_generate_mindmap(note_content)
    except Exception as e:
        # å…¶ä»–é”™è¯¯ï¼Œè¿”å›ç®€å•ç»“æ„
        return {
            "id": "root",
            "text": "ç¬”è®°æ¦‚è¦",
            "children": [
                {"id": "node1", "text": "å†…å®¹è¦ç‚¹1", "children": []},
                {"id": "node2", "text": "å†…å®¹è¦ç‚¹2", "children": []}
            ]
        }

def validate_mindmap_structure(structure: dict):
    """éªŒè¯è„‘å›¾ç»“æ„"""
    required_fields = ["id", "text", "children"]
    for field in required_fields:
        if field not in structure:
            raise ValueError(f"Missing required field: {field}")

    if not isinstance(structure["children"], list):
        raise ValueError("children must be a list")

    # é€’å½’éªŒè¯å­èŠ‚ç‚¹
    for child in structure["children"]:
        validate_mindmap_structure(child)
```

#### 3. å¼‚æ­¥ä»»åŠ¡å¤„ç†
```python
# app/api/mindmaps.py
from fastapi import APIRouter, Depends, BackgroundTasks
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.models.user import User
from app.api.dependencies import get_current_user
from app.services.mindmap_generator import generate_mindmap
from app.models.note import Note
from app.models.mindmap import Mindmap

router = APIRouter(prefix="/api/mindmaps", tags=["mindmaps"])

@router.post("/generate/{note_id}")
async def generate_mindmap_for_note(
    note_id: str,
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    # æ£€æŸ¥ç¬”è®°æ˜¯å¦å­˜åœ¨
    note = db.query(Note).filter(Note.id == note_id, Note.user_id == current_user.id).first()
    if not note:
        raise HTTPException(status_code=404, detail="Note not found")

    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è„‘å›¾
    existing = db.query(Mindmap).filter(Mindmap.note_id == note_id).first()
    if existing:
        return {"mindmap_id": existing.id, "status": "already_exists"}

    # å¼‚æ­¥ç”Ÿæˆ
    background_tasks.add_task(generate_and_save_mindmap, note_id, current_user.id, db)

    return {"task_id": note_id, "status": "processing"}

async def generate_and_save_mindmap(note_id: str, user_id: str, db: Session):
    """åå°ä»»åŠ¡ï¼šç”Ÿæˆå¹¶ä¿å­˜è„‘å›¾"""
    note = db.query(Note).filter(Note.id == note_id).first()
    if not note:
        return

    # ç”Ÿæˆè„‘å›¾
    structure = await generate_mindmap(note.ocr_text, note_id)

    # ä¿å­˜åˆ°æ•°æ®åº“
    mindmap = Mindmap(
        user_id=user_id,
        note_id=note_id,
        structure=structure,
        map_type="ai_generated",
        ai_model="deepseek-chat",
        ai_generated_at=datetime.utcnow()
    )
    db.add(mindmap)
    db.commit()

    # æå–çŸ¥è¯†ç‚¹
    await extract_knowledge_points(mindmap, note, db)

    # WebSocketé€šçŸ¥ï¼ˆå¯é€‰ï¼‰
    await notify_mindmap_ready(user_id, mindmap.id)
```

#### 4. çŸ¥è¯†ç‚¹æå–
```python
# app/services/knowledge_extractor.py
async def extract_knowledge_points(mindmap: Mindmap, note: Note, db: Session):
    """ä»è„‘å›¾ä¸­æå–çŸ¥è¯†ç‚¹"""
    def traverse_and_extract(node: dict, parent_id: str = None):
        """é€’å½’éå†è„‘å›¾èŠ‚ç‚¹"""
        # åˆ›å»ºçŸ¥è¯†ç‚¹è®°å½•
        kp = MindmapKnowledgePoint(
            mindmap_id=mindmap.id,
            node_id=node["id"],
            knowledge_text=node["text"],
            related_note_id=note.id
        )
        db.add(kp)
        db.flush()  # è·å–kp.id

        # é€’å½’å¤„ç†å­èŠ‚ç‚¹
        for child in node.get("children", []):
            traverse_and_extract(child, kp.id)

    # å¼€å§‹éå†
    traverse_and_extract(mindmap.structure)
    db.commit()
```

### âœ… éªŒæ”¶æ ‡å‡†

- [ ] **è„‘å›¾ç”ŸæˆæˆåŠŸ**: AIè¿”å›æœ‰æ•ˆçš„JSONç»“æ„
- [ ] **å±‚çº§æ­£ç¡®**: æœ€å¤š5çº§ï¼Œæ¯çº§2-5ä¸ªèŠ‚ç‚¹
- [ ] **å‰ç«¯æ¸²æŸ“**: è„‘å›¾åœ¨å‰ç«¯æ­£ç¡®æ˜¾ç¤º
- [ ] **æˆæœ¬æ§åˆ¶**: AIè°ƒç”¨æˆæœ¬<$0.01/æ¬¡
- [ ] **ç”Ÿæˆé€Ÿåº¦**: 10ç§’å†…å®Œæˆ
- [ ] **ç‰ˆæœ¬å†å²**: æ”¯æŒæŸ¥çœ‹å†å²ç‰ˆæœ¬
- [ ] **ç¼“å­˜ç”Ÿæ•ˆ**: 24å°æ—¶å†…é‡å¤è¯·æ±‚è¿”å›ç¼“å­˜

### ğŸ”— ç›¸å…³èµ„æº

- DeepSeek API: https://platform.deepseek.com/api-docs/
- OpenAI API: https://platform.openai.com/docs/
- D3.jsï¼ˆè„‘å›¾å¯è§†åŒ–ï¼‰: https://d3js.org/

---

## #6 åŸºäºè„‘å›¾çš„çŸ¥è¯†ç‚¹æé—®ç³»ç»Ÿ

**ä¼˜å…ˆçº§**: P1
**é¢„è®¡å·¥æœŸ**: 5-7å¤©
**ä¾èµ–**: ä»»åŠ¡#5ï¼ˆAIè„‘å›¾ç”Ÿæˆï¼‰
**è´Ÿè´£è§’è‰²**: åç«¯å·¥ç¨‹å¸ˆ + AIå·¥ç¨‹å¸ˆ

### ğŸ“Œ ä»»åŠ¡ç›®æ ‡

æ ¹æ®è„‘å›¾çš„çŸ¥è¯†ç‚¹ç»“æ„ï¼Œä½¿ç”¨AIç”Ÿæˆäº¤äº’å¼æµ‹è¯•é¢˜ï¼Œæ”¯æŒå¤šç§é¢˜å‹ï¼Œè‡ªåŠ¨å®šä½é”™é¢˜åˆ°ç¬”è®°ç›¸å…³å†…å®¹ã€‚

### ğŸ“ åŠŸèƒ½éœ€æ±‚

#### 1. é¢˜ç›®ç”Ÿæˆ
- éå†mindmap_knowledge_pointsè¡¨
- å¯¹æ¯ä¸ªçŸ¥è¯†ç‚¹è°ƒç”¨LLMç”Ÿæˆé¢˜ç›®
- æ”¯æŒå¤šç§é¢˜å‹ï¼šé€‰æ‹©é¢˜ã€å¡«ç©ºé¢˜ã€ç®€ç­”é¢˜
- åŸºäºç¬”è®°å†…å®¹ç”Ÿæˆé¢˜ç›®å’Œç­”æ¡ˆ
- ä½¿ç”¨å‘é‡æœç´¢å®šä½ç›¸å…³ç¬”è®°ç‰‡æ®µ

#### 2. ç­”æ¡ˆéªŒè¯
- **é€‰æ‹©é¢˜**: ç›´æ¥åŒ¹é…é€‰é¡¹
- **å¡«ç©ºé¢˜**: æ¨¡ç³ŠåŒ¹é…ï¼ˆå…³é”®è¯ï¼‰
- **ç®€ç­”é¢˜**: ä½¿ç”¨LLMè¯„åˆ†

#### 3. é”™é¢˜å®šä½
- ç­”é”™æ—¶ä½¿ç”¨å‘é‡æ£€ç´¢
- ä»ChromaDBæœç´¢ç›¸å…³ç¬”è®°æ®µè½
- è¿”å›ç¬”è®°ç‰‡æ®µå’Œä½ç½®

#### 4. ç­”é¢˜è®°å½•
- è®°å½•ç”¨æˆ·ç­”æ¡ˆ
- ç»Ÿè®¡æ­£ç¡®ç‡
- è‡ªåŠ¨åŠ å…¥é”™é¢˜åº“

### ğŸ”Œ APIç«¯ç‚¹è®¾è®¡

#### 1. ç”Ÿæˆæµ‹éªŒé¢˜
```
POST /api/quizzes/generate/{mindmap_id}
Authorization: Bearer {access_token}

Request:
{
  "question_count": 10,
  "question_types": ["choice", "fill_blank"],
  "difficulty": "medium"
}

Response 202:
{
  "quiz_id": "uuid",
  "status": "generating",
  "total_questions": 10
}
```

#### 2. è·å–æµ‹éªŒè¯¦æƒ…
```
GET /api/quizzes/{quiz_id}
Authorization: Bearer {access_token}

Response 200:
{
  "id": "uuid",
  "mindmap_id": "uuid",
  "questions": [
    {
      "id": "uuid",
      "knowledge_point_id": "uuid",
      "question_text": "å¯¼æ•°çš„å®šä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ",
      "question_type": "choice",
      "options": [
        "A. ç¬æ—¶å˜åŒ–ç‡",
        "B. å¹³å‡å˜åŒ–ç‡",
        "C. ç´¯ç§¯å˜åŒ–ç‡",
        "D. æ€»é‡å˜åŒ–ç‡"
      ],
      "difficulty": "medium"
    }
  ],
  "created_at": "2026-02-08T10:30:00Z"
}
```

#### 3. æäº¤ç­”æ¡ˆ
```
POST /api/quizzes/{quiz_id}/answer
Authorization: Bearer {access_token}
Content-Type: application/json

Request:
{
  "answers": [
    {
      "question_id": "uuid",
      "user_answer": "A"
    }
  ]
}

Response 200:
{
  "quiz_id": "uuid",
  "total_questions": 10,
  "correct_count": 7,
  "incorrect_count": 3,
  "accuracy": 0.7,
  "results": [
    {
      "question_id": "uuid",
      "user_answer": "A",
      "correct_answer": "A",
      "is_correct": true
    },
    {
      "question_id": "uuid",
      "user_answer": "B",
      "correct_answer": "A",
      "is_correct": false,
      "related_note_snippet": "å¯¼æ•°æ˜¯å‡½æ•°åœ¨æŸä¸€ç‚¹çš„ç¬æ—¶å˜åŒ–ç‡...",
      "related_note_section": "ç¬¬ä¸€ç«  1.2èŠ‚"
    }
  ]
}
```

#### 4. æŸ¥çœ‹ç­”é¢˜ç»Ÿè®¡
```
GET /api/quizzes/{quiz_id}/results
Authorization: Bearer {access_token}

Response 200:
{
  "quiz_id": "uuid",
  "total_questions": 10,
  "correct_count": 7,
  "incorrect_count": 3,
  "accuracy": 0.7,
  "time_spent": 300,
  "weak_points": [
    {
      "knowledge_point_id": "uuid",
      "knowledge_text": "å¯¼æ•°å®šä¹‰",
      "error_count": 2,
      "accuracy": 0.5
    }
  ]
}
```

### ğŸ’» æŠ€æœ¯å®ç°

#### 1. AI Promptè®¾è®¡
```python
# app/prompts/quiz.py
QUIZ_GENERATION_PROMPT = """è¯·æ ¹æ®ä»¥ä¸‹çŸ¥è¯†ç‚¹ç”Ÿæˆä¸€é“{question_type}ï¼š

**çŸ¥è¯†ç‚¹**: {knowledge_text}
**ç›¸å…³ç¬”è®°**: {related_note_content}

è¦æ±‚ï¼š
1. é¢˜ç›®éš¾åº¦é€‚ä¸­ï¼ˆ{difficulty}ï¼‰
2. æµ‹è¯•å¯¹è¯¥çŸ¥è¯†ç‚¹çš„ç†è§£
3. è¿”å›JSONæ ¼å¼

{extra_requirements}

JSONæ ¼å¼ï¼š
{{
  "question": "é¢˜ç›®æ–‡æœ¬",
  "options": ["A. é€‰é¡¹1", "B. é€‰é¡¹2", "C. é€‰é¡¹3", "D. é€‰é¡¹4"],
  "correct_answer": "A",
  "explanation": "ç­”æ¡ˆè§£æ"
}}

è¯·ç”Ÿæˆé¢˜ç›®ï¼ˆåªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼‰ï¼š"""

# é€‰æ‹©é¢˜é¢å¤–è¦æ±‚
CHOICE_REQUIREMENTS = """
- 4ä¸ªé€‰é¡¹ï¼Œåªæœ‰1ä¸ªæ­£ç¡®ç­”æ¡ˆ
- é€‰é¡¹è¦æœ‰å¹²æ‰°æ€§ï¼Œä½†ä¸èƒ½æ˜æ˜¾é”™è¯¯
- ç­”æ¡ˆè§£æè¦è¯´æ˜ä¸ºä»€ä¹ˆé€‰è¿™ä¸ªç­”æ¡ˆ
"""

# å¡«ç©ºé¢˜é¢å¤–è¦æ±‚
FILL_BLANK_REQUIREMENTS = """
- 1-2ä¸ªç©ºéœ€è¦å¡«å†™
- ç­”æ¡ˆæ˜¯å…³é”®è¯æˆ–çŸ­è¯­
- æä¾›å®Œæ•´çš„ç­”æ¡ˆï¼ˆåŒ…æ‹¬æ‰€æœ‰å¯èƒ½çš„å˜ä½“ï¼‰
"""

# ç®€ç­”é¢˜é¢å¤–è¦æ±‚
ESSAY_REQUIREMENTS = """
- ç­”æ¡ˆé•¿åº¦100-200å­—
- è¦ç‚¹æ¸…æ™°ï¼Œé€»è¾‘å®Œæ•´
- æä¾›è¯„åˆ†æ ‡å‡†ï¼ˆå…³é”®è¯ï¼‰
"""
```

#### 2. é¢˜ç›®ç”ŸæˆæœåŠ¡
```python
# app/services/quiz_generator.py
from openai import AsyncOpenAI
from app.prompts.quiz import QUIZ_GENERATION_PROMPT, CHOICE_REQUIREMENTS
import json

client = AsyncOpenAI(api_key=settings.DEEPSEEK_API_KEY, base_url="https://api.deepseek.com")

async def generate_question(knowledge_point: MindmapKnowledgePoint, question_type: str, difficulty: str):
    """ç”Ÿæˆå•ä¸ªé¢˜ç›®"""
    # è·å–ç›¸å…³ç¬”è®°
    note = db.query(Note).filter(Note.id == knowledge_point.related_note_id).first()
    note_content = note.ocr_text if note else ""

    # é€‰æ‹©promptæ¨¡æ¿
    extra_requirements = {
        "choice": CHOICE_REQUIREMENTS,
        "fill_blank": FILL_BLANK_REQUIREMENTS,
        "essay": ESSAY_REQUIREMENTS
    }.get(question_type, "")

    # æ„å»ºprompt
    prompt = QUIZ_GENERATION_PROMPT.format(
        knowledge_text=knowledge_point.knowledge_text,
        related_note_content=note_content[:1000],
        question_type=question_type,
        difficulty=difficulty,
        extra_requirements=extra_requirements
    )

    # è°ƒç”¨AI
    response = await client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•™è‚²é¢˜ç›®ç”ŸæˆåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.5,
        max_tokens=500
    )

    result = response.choices[0].message.content

    # è§£æJSON
    question_data = parse_json_response(result)

    # ä¿å­˜åˆ°æ•°æ®åº“
    question = QuizQuestion(
        knowledge_point_id=knowledge_point.id,
        note_id=knowledge_point.related_note_id,
        question_text=question_data["question"],
        question_type=question_type,
        options=json.dumps(question_data.get("options", [])) if question_type == "choice" else None,
        correct_answer=question_data["correct_answer"],
        answer_explanation=question_data.get("explanation"),
        difficulty=difficulty,
        ai_generated=True
    )
    db.add(question)
    db.commit()
    db.refresh(question)

    return question
```

#### 3. ç­”æ¡ˆéªŒè¯
```python
# app/services/quiz_validator.py

async def validate_answer(question: QuizQuestion, user_answer: str):
    """éªŒè¯ç”¨æˆ·ç­”æ¡ˆ"""
    if question.question_type == "choice":
        # é€‰æ‹©é¢˜ï¼šç›´æ¥åŒ¹é…
        is_correct = user_answer.strip().upper() == question.correct_answer.strip().upper()
        return is_correct, None

    elif question.question_type == "fill_blank":
        # å¡«ç©ºé¢˜ï¼šæ¨¡ç³ŠåŒ¹é…
        correct_answers = question.correct_answer.split("/")  # æ”¯æŒå¤šä¸ªæ­£ç¡®ç­”æ¡ˆ
        is_correct = any(
            user_answer.strip().lower() == ans.strip().lower()
            for ans in correct_answers
        )
        return is_correct, None

    elif question.question_type == "essay":
        # ç®€ç­”é¢˜ï¼šä½¿ç”¨LLMè¯„åˆ†
        return await grade_essay_answer(question, user_answer)

def grade_essay_answer(question: QuizQuestion, user_answer: str):
    """ä½¿ç”¨LLMè¯„åˆ†ç®€ç­”é¢˜"""
    prompt = f"""è¯·è¯„åˆ¤ä»¥ä¸‹ç­”æ¡ˆæ˜¯å¦æ­£ç¡®ï¼š

**é—®é¢˜**: {question.question_text}
**æ ‡å‡†ç­”æ¡ˆ**: {question.correct_answer}
**å­¦ç”Ÿç­”æ¡ˆ**: {user_answer}

è¦æ±‚ï¼š
1. è¿”å›JSONæ ¼å¼
2. åŒ…å«is_correctï¼ˆtrue/falseï¼‰å’Œfeedbackï¼ˆè¯„è¯­ï¼‰

JSONæ ¼å¼ï¼š
{{
  "is_correct": true/false,
  "feedback": "è¯„è¯­"
}}
"""

    response = await client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_tokens=200
    )

    result = parse_json_response(response.choices[0].message.content)
    return result["is_correct"], result["feedback"]
```

#### 4. é”™é¢˜å®šä½ï¼ˆå‘é‡æœç´¢ï¼‰
```python
# app/services/mistake_locator.py
import chromadb

client = chromadb.Client()
collection = client.get_or_create_collection("notes")

async def locate_relevant_note_content(question_text: str, user_id: str):
    """ä½¿ç”¨å‘é‡æœç´¢å®šä½ç›¸å…³ç¬”è®°å†…å®¹"""
    # ç”Ÿæˆé—®é¢˜å‘é‡
    question_embedding = await generate_embedding(question_text)

    # åœ¨ChromaDBä¸­æœç´¢
    results = collection.query(
        query_embeddings=[question_embedding],
        n_results=3,
        where={"user_id": user_id}
    )

    if results["distances"][0][0] < 0.3:  # ç›¸ä¼¼åº¦é˜ˆå€¼
        return {
            "note_id": results["ids"][0][0],
            "snippet": results["documents"][0][0][:500],
            "score": 1 - results["distances"][0][0]
        }

    return None
```

### âœ… éªŒæ”¶æ ‡å‡†

- [ ] **é¢˜ç›®ç”ŸæˆæˆåŠŸ**: AIç”Ÿæˆæœ‰æ•ˆçš„é¢˜ç›®
- [ ] **é€‰æ‹©é¢˜å‡†ç¡®**: é€‰é¡¹å’Œç­”æ¡ˆæ­£ç¡®
- [ ] **å¡«ç©ºé¢˜æ¨¡ç³ŠåŒ¹é…**: å…³é”®è¯åŒ¹é…æ­£ç¡®
- [ ] **ç®€ç­”é¢˜è¯„åˆ†åˆç†**: LLMè¯„åˆ†ä¸äººå·¥è¯„åˆ†ä¸€è‡´
- [ ] **é”™é¢˜å®šä½å‡†ç¡®**: å‘é‡æœç´¢è¿”å›ç›¸å…³ç¬”è®°æ®µè½
- [ ] **ç­”é¢˜è®°å½•å­˜å‚¨**: æ­£ç¡®ä¿å­˜åˆ°æ•°æ®åº“
- [ ] **ç»Ÿè®¡åŠŸèƒ½**: æ­£ç¡®ç‡ã€è–„å¼±ç‚¹åˆ†æå‡†ç¡®

---

## #3 é”™é¢˜åº“ç®¡ç†ä¸æ™ºèƒ½åˆ†æ

**ä¼˜å…ˆçº§**: P1
**é¢„è®¡å·¥æœŸ**: 6-8å¤©
**ä¾èµ–**: ä»»åŠ¡#6ï¼ˆçŸ¥è¯†ç‚¹æé—®ï¼‰
**è´Ÿè´£è§’è‰²**: åç«¯å·¥ç¨‹å¸ˆ

### ğŸ“Œ ä»»åŠ¡ç›®æ ‡

å®ç°é”™é¢˜æ”¶é›†ã€ç®¡ç†ã€æ™ºèƒ½åˆ†æè–„å¼±çŸ¥è¯†ç‚¹ï¼Œæä¾›åŸºäºè‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿çš„å¤ä¹ æé†’ã€‚

### ğŸ“ åŠŸèƒ½éœ€æ±‚

#### 1. é”™é¢˜æ”¶é›†
- æ‰‹åŠ¨æ·»åŠ é”™é¢˜ï¼ˆä¸Šä¼ å›¾ç‰‡/æ–‡æœ¬ï¼‰
- ä»æµ‹éªŒé”™é¢˜è‡ªåŠ¨åŠ å…¥
- é”™é¢˜æ ‡ç­¾ä¸åˆ†ç±»
- å…³è”çŸ¥è¯†ç‚¹

#### 2. é”™é¢˜ç®¡ç†
- é”™é¢˜åˆ—è¡¨ï¼ˆåˆ†é¡µã€ç­›é€‰ã€æ’åºï¼‰
- é”™é¢˜è¯¦æƒ…
- ç¼–è¾‘/åˆ é™¤é”™é¢˜
- æ‰¹é‡æ“ä½œ

#### 3. å¤ä¹ æ¨¡å¼
- æŒ‰æ—¶é—´é¡ºåºå¤ä¹ 
- æŒ‰çŸ¥è¯†ç‚¹å¤ä¹ 
- æŒ‰é”™è¯¯æ¬¡æ•°å¤ä¹ 
- éšæœºå¤ä¹ 

#### 4. è–„å¼±ç‚¹åˆ†æ
- ç»Ÿè®¡æ¯ä¸ªçŸ¥è¯†ç‚¹çš„é”™è¯¯ç‡
- å…³è”è„‘å›¾æ˜¾ç¤ºè–„å¼±åŒºåŸŸ
- ç”Ÿæˆå¤ä¹ å»ºè®®

#### 5. å¤ä¹ æé†’
- åŸºäºè‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿
- é”™é¢˜å20åˆ†é’Ÿã€1å°æ—¶ã€9å°æ—¶ã€1å¤©ã€2å¤©ã€6å¤©ã€31å¤©æé†’
- é‚®ä»¶/ç«™å†…ä¿¡é€šçŸ¥

### ğŸ”Œ APIç«¯ç‚¹è®¾è®¡

#### 1. æ·»åŠ é”™é¢˜
```
POST /api/mistakes
Authorization: Bearer {access_token}
Content-Type: application/json

Request:
{
  "question_id": "uuid",  // å¦‚æœä»quizæ·»åŠ 
  "question_text": "å¯¼æ•°çš„å®šä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ",
  "question_type": "choice",
  "options": ["A. xxx", "B. xxx", "C. xxx", "D. xxx"],
  "correct_answer": "A",
  "user_answer": "B",
  "tags": ["æ•°å­¦", "å¾®ç§¯åˆ†", "å¯¼æ•°"],
  "category_id": "uuid",
  "knowledge_point_id": "uuid"
}

Response 201:
{
  "id": "uuid",
  "question_text": "å¯¼æ•°çš„å®šä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ",
  "mistake_count": 1,
  "last_mistake_at": "2026-02-08T10:30:00Z",
  "created_at": "2026-02-08T10:30:00Z"
}
```

#### 2. è·å–é”™é¢˜åˆ—è¡¨
```
GET /api/mistakes?page=1&limit=20&tags=å¾®ç§¯åˆ†&sort=last_mistake_at
Authorization: Bearer {access_token}

Response 200:
{
  "total": 45,
  "page": 1,
  "limit": 20,
  "mistakes": [
    {
      "id": "uuid",
      "question_text": "å¯¼æ•°çš„å®šä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ",
      "question_type": "choice",
      "tags": ["æ•°å­¦", "å¾®ç§¯åˆ†"],
      "mistake_count": 3,
      "last_mistake_at": "2026-02-08T10:30:00Z",
      "category": {
        "id": "uuid",
        "name": "æ•°å­¦"
      },
      "knowledge_point": {
        "id": "uuid",
        "text": "å¯¼æ•°å®šä¹‰"
      }
    }
  ]
}
```

#### 3. è·å–é”™é¢˜è¯¦æƒ…
```
GET /api/mistakes/{mistake_id}
Authorization: Bearer {access_token}

Response 200:
{
  "id": "uuid",
  "question_text": "å¯¼æ•°çš„å®šä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ",
  "question_type": "choice",
  "options": ["A. xxx", "B. xxx", "C. xxx", "D. xxx"],
  "correct_answer": "A",
  "user_answer": "B",
  "tags": ["æ•°å­¦", "å¾®ç§¯åˆ†"],
  "category": {...},
  "knowledge_point": {...},
  "related_note": {
    "id": "uuid",
    "title": "å¾®ç§¯åˆ†ç¬”è®°ç¬¬ä¸€ç« ",
    "snippet": "å¯¼æ•°æ˜¯å‡½æ•°åœ¨æŸä¸€ç‚¹çš„ç¬æ—¶å˜åŒ–ç‡..."
  },
  "mistake_count": 3,
  "review_history": [
    {
      "reviewed_at": "2026-02-07T10:00:00Z",
      "is_correct": false
    }
  ],
  "next_review_at": "2026-02-08T11:00:00Z",
  "created_at": "2026-02-06T10:30:00Z"
}
```

#### 4. æ›´æ–°é”™é¢˜
```
PUT /api/mistakes/{mistake_id}
Authorization: Bearer {access_token}
Content-Type: application/json

Request:
{
  "tags": ["æ•°å­¦", "å¾®ç§¯åˆ†", "å¯¼æ•°", "é‡ç‚¹"],
  "category_id": "uuid"
}

Response 200:
{
  "id": "uuid",
  "tags": ["æ•°å­¦", "å¾®ç§¯åˆ†", "å¯¼æ•°", "é‡ç‚¹"],
  "updated_at": "2026-02-08T11:00:00Z"
}
```

#### 5. åˆ é™¤é”™é¢˜
```
DELETE /api/mistakes/{mistake_id}
Authorization: Bearer {access_token}

Response 204
```

#### 6. è·å–è–„å¼±ç‚¹åˆ†æ
```
GET /api/mistakes/analysis
Authorization: Bearer {access_token}

Response 200:
{
  "total_mistakes": 45,
  "weak_points": [
    {
      "knowledge_point_id": "uuid",
      "knowledge_text": "å¯¼æ•°å®šä¹‰",
      "error_count": 8,
      "total_questions": 10,
      "error_rate": 0.8,
      "rank": 1
    },
    {
      "knowledge_point_id": "uuid",
      "knowledge_text": "æ±‚å¯¼æ³•åˆ™",
      "error_count": 5,
      "total_questions": 10,
      "error_rate": 0.5,
      "rank": 2
    }
  ],
  "category_breakdown": [
    {
      "category_id": "uuid",
      "category_name": "æ•°å­¦",
      "mistake_count": 30,
      "percentage": 0.67
    },
    {
      "category_id": "uuid",
      "category_name": "è‹±è¯­",
      "mistake_count": 15,
      "percentage": 0.33
    }
  ]
}
```

#### 7. å¤ä¹ é”™é¢˜
```
POST /api/mistakes/{mistake_id}/review
Authorization: Bearer {access_token}
Content-Type: application/json

Request:
{
  "user_answer": "A",
  "time_spent": 30
}

Response 200:
{
  "mistake_id": "uuid",
  "is_correct": true,
  "review_stage": 1,
  "next_review_at": "2026-02-08T20:00:00Z",
  "message": "æ­å–œï¼ä¸‹æ¬¡å¤ä¹ æ—¶é—´ï¼šä»Šå¤©20:00"
}
```

#### 8. è·å–å¾…å¤ä¹ é”™é¢˜
```
GET /api/mistakes/review-due
Authorization: Bearer {access_token}

Response 200:
{
  "total": 12,
  "mistakes": [
    {
      "id": "uuid",
      "question_text": "å¯¼æ•°çš„å®šä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ",
      "next_review_at": "2026-02-08T10:30:00Z",
      "review_stage": 0
    }
  ]
}
```

### ğŸ’» æŠ€æœ¯å®ç°

#### 1. è–„å¼±ç‚¹åˆ†æç®—æ³•
```python
# app/services/weakness_analyzer.py
from sqlalchemy import func
from app.models.mistake import Mistake
from app.models.quiz import QuizQuestion

def analyze_weak_points(user_id: str, db: Session):
    """åˆ†æç”¨æˆ·è–„å¼±çŸ¥è¯†ç‚¹"""
    # 1. è·å–æ‰€æœ‰é”™é¢˜
    mistakes = db.query(Mistake).filter(Mistake.user_id == user_id).all()

    # 2. æŒ‰çŸ¥è¯†ç‚¹åˆ†ç»„ç»Ÿè®¡
    error_stats = {}
    for mistake in mistakes:
        kp_id = mistake.knowledge_point_id
        if not kp_id:
            continue

        if kp_id not in error_stats:
            error_stats[kp_id] = {
                "knowledge_point_id": kp_id,
                "error_count": 0,
                "mistakes": []
            }

        error_stats[kp_id]["error_count"] += 1
        error_stats[kp_id]["mistakes"].append(mistake)

    # 3. è®¡ç®—é”™è¯¯ç‡
    for kp_id, stats in error_stats.items():
        # è·å–è¯¥çŸ¥è¯†ç‚¹æ€»é¢˜ç›®æ•°
        total_questions = db.query(func.count(QuizQuestion.id)).filter(
            QuizQuestion.knowledge_point_id == kp_id
        ).scalar()

        # è®¡ç®—é”™è¯¯ç‡
        error_rate = stats["error_count"] / total_questions if total_questions > 0 else 0
        stats["total_questions"] = total_questions
        stats["error_rate"] = error_rate

    # 4. æ’åºå¹¶è¿”å›TOP10
    weak_points = sorted(
        error_stats.values(),
        key=lambda x: x["error_rate"],
        reverse=True
    )[:10]

    return weak_points
```

#### 2. è‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿å¤ä¹ è°ƒåº¦
```python
# app/services/review_scheduler.py
from datetime import timedelta

# è‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿å¤ä¹ é—´éš”ï¼ˆå•ä½ï¼šåˆ†é’Ÿï¼‰
REVIEW_INTERVALS = [20, 60, 540, 1440, 2880, 8640, 44640]  # 20åˆ†é’Ÿã€1å°æ—¶ã€9å°æ—¶ã€1å¤©ã€2å¤©ã€6å¤©ã€31å¤©

def schedule_next_review(mistake: Mistake, is_correct: bool):
    """å®‰æ’ä¸‹æ¬¡å¤ä¹ æ—¶é—´"""
    if is_correct:
        # ç­”å¯¹äº†ï¼Œè¿›å…¥ä¸‹ä¸€é˜¶æ®µ
        next_stage = mistake.review_stage + 1
        if next_stage < len(REVIEW_INTERVALS):
            interval_minutes = REVIEW_INTERVALS[next_stage]
            next_review_at = datetime.utcnow() + timedelta(minutes=interval_minutes)
        else:
            # å·²å®Œæˆæ‰€æœ‰å¤ä¹ é˜¶æ®µ
            next_review_at = None
    else:
        # ç­”é”™äº†ï¼Œé‡ç½®åˆ°ç¬¬ä¸€é˜¶æ®µ
        next_stage = 0
        interval_minutes = REVIEW_INTERVALS[0]
        next_review_at = datetime.utcnow() + timedelta(minutes=interval_minutes)

    return next_review_at, next_stage

async def create_mistake_review(mistake_id: str, user_answer: str, is_correct: bool, db: Session):
    """åˆ›å»ºé”™é¢˜å¤ä¹ è®°å½•"""
    mistake = db.query(Mistake).filter(Mistake.id == mistake_id).first()
    if not mistake:
        raise HTTPException(status_code=404, detail="Mistake not found")

    # è®¡ç®—ä¸‹æ¬¡å¤ä¹ æ—¶é—´
    next_review_at, next_stage = schedule_next_review(mistake, is_correct)

    # åˆ›å»ºå¤ä¹ è®°å½•
    review = MistakeReview(
        mistake_id=mistake_id,
        user_id=mistake.user_id,
        is_correct=is_correct,
        review_stage=next_stage,
        next_review_at=next_review_at
    )
    db.add(review)

    # æ›´æ–°é”™é¢˜
    mistake.mistake_count += 1 if not is_correct else 0
    mistake.last_mistake_at = datetime.utcnow() if not is_correct else mistake.last_mistake_at

    db.commit()
    db.refresh(review)

    return review
```

#### 3. å¤ä¹ æé†’ä»»åŠ¡
```python
# app/tasks/review_reminder.py
from apscheduler.schedulers.asyncio import AsyncIOScheduler

scheduler = AsyncIOScheduler()

async def send_review_reminders():
    """å‘é€å¤ä¹ æé†’"""
    now = datetime.utcnow()

    # æŸ¥æ‰¾éœ€è¦å¤ä¹ çš„é”™é¢˜
    due_reviews = db.query(MistakeReview).filter(
        MistakeReview.next_review_at <= now,
        MistakeReview.next_review_at > now - timedelta(minutes=5)  # 5åˆ†é’Ÿçª—å£
    ).all()

    for review in due_reviews:
        user = db.query(User).filter(User.id == review.user_id).first()
        mistake = db.query(Mistake).filter(Mistake.id == review.mistake_id).first()

        # å‘é€ç«™å†…ä¿¡
        await send_in_app_notification(
            user_id=user.id,
            title="å¤ä¹ æé†’",
            message=f"æ‚¨æœ‰{len(due_reviews)}é“é”™é¢˜éœ€è¦å¤ä¹ ",
            link=f"/mistakes/review"
        )

        # å‘é€é‚®ä»¶ï¼ˆå¯é€‰ï¼‰
        if user.email_notifications_enabled:
            await send_email(
                to=user.email,
                subject="å¤ä¹ æé†’",
                body=f"æ‚¨æœ‰{len(due_reviews)}é“é”™é¢˜éœ€è¦å¤ä¹ ï¼Œç‚¹å‡»æŸ¥çœ‹ï¼šhttps://app.example.com/mistakes/review"
            )

# æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡
scheduler.add_job(send_review_reminders, 'interval', hours=1)
scheduler.start()
```

### âœ… éªŒæ”¶æ ‡å‡†

- [ ] **é”™é¢˜æ·»åŠ æˆåŠŸ**: æ‰‹åŠ¨æ·»åŠ å’Œè‡ªåŠ¨æ·»åŠ éƒ½æ­£å¸¸
- [ ] **è–„å¼±ç‚¹åˆ†æå‡†ç¡®**: é”™è¯¯ç‡è®¡ç®—æ­£ç¡®
- [ ] **è„‘å›¾æ ‡è¯†**: è„‘å›¾ä¸Šæ­£ç¡®æ ‡è¯†è–„å¼±åŒºåŸŸ
- [ ] **å¤ä¹ æé†’æŒ‰æ—¶è§¦å‘**: è‰¾å®¾æµ©æ–¯æ›²çº¿æ­£ç¡®è®¡ç®—
- [ ] **å¤ä¹ åŠŸèƒ½å®Œå–„**: æ”¯æŒå¤šç§å¤ä¹ æ¨¡å¼
- [ ] **é”™é¢˜ä¸ç¬”è®°å…³è”**: è‡ªåŠ¨å®šä½åˆ°ç›¸å…³ç¬”è®°å†…å®¹

---

## #4 ç¬”è®°åˆ†äº«ä¸åä½œåŠŸèƒ½

**ä¼˜å…ˆçº§**: P2
**é¢„è®¡å·¥æœŸ**: 7-10å¤©
**ä¾èµ–**: ä»»åŠ¡#10ï¼ˆç¬”è®°ä¸Šä¼ ï¼‰
**è´Ÿè´£è§’è‰²**: åç«¯å·¥ç¨‹å¸ˆ

### ğŸ“Œ ä»»åŠ¡ç›®æ ‡

å®ç°ç¬”è®°åˆ†äº«ã€ä¸‹è½½ã€æ™ºèƒ½åˆå¹¶ï¼Œæ”¯æŒå®æ—¶åä½œç¼–è¾‘ç¬”è®°ã€‚

### ğŸ“ åŠŸèƒ½éœ€æ±‚

#### 1. ç¬”è®°åˆ†äº«
- ç”Ÿæˆåˆ†äº«é“¾æ¥
- è®¾ç½®è®¿é—®æƒé™ï¼ˆå…¬å¼€/å¯†ç /ä»…æŒ‡å®šç”¨æˆ·ï¼‰
- è®¾ç½®è¿‡æœŸæ—¶é—´
- è®¿é—®ç»Ÿè®¡ï¼ˆæµè§ˆã€ä¸‹è½½ã€åˆå¹¶æ¬¡æ•°ï¼‰

#### 2. è®¿é—®æ§åˆ¶
- å…¬å¼€è®¿é—®
- å¯†ç ä¿æŠ¤
- ä»…æŒ‡å®šç”¨æˆ·å¯è®¿é—®

#### 3. ä¸‹è½½ä»–äººç¬”è®°
- æµè§ˆå…¬å¼€ç¬”è®°
- æœç´¢ç¬”è®°
- ä¸‹è½½ç¬”è®°åˆ°æœ¬åœ°

#### 4. æ™ºèƒ½åˆå¹¶
- è®¡ç®—ç¬”è®°ç›¸ä¼¼åº¦
- æ™ºèƒ½å»é‡
- åˆ†ç±»é€‚é…
- ç‰ˆæœ¬åˆå¹¶

#### 5. å®æ—¶åä½œ
- å¤šäººåŒæ—¶ç¼–è¾‘ç¬”è®°
- å®æ—¶åŒæ­¥ä¿®æ”¹
- å†²çªè§£å†³
- ä½¿ç”¨Yjså®ç°CRDT

### ğŸ”Œ APIç«¯ç‚¹è®¾è®¡

#### 1. åˆ›å»ºåˆ†äº«é“¾æ¥
```
POST /api/notes/{note_id}/share
Authorization: Bearer {access_token}
Content-Type: application/json

Request:
{
  "access_type": "public",  // public, password, restricted
  "password": "password123",  // access_type=passwordæ—¶å¿…å¡«
  "allow_download": true,
  "allow_merge": true,
  "expires_at": "2026-03-08T00:00:00Z"
}

Response 201:
{
  "id": "uuid",
  "share_id": "abc123",
  "share_url": "https://app.example.com/share/abc123",
  "access_type": "public",
  "qr_code": "data:image/png;base64,...",
  "created_at": "2026-02-08T10:30:00Z"
}
```

#### 2. è®¿é—®åˆ†äº«ç¬”è®°
```
GET /api/notes/share/{share_id}
Response 200:

// å¦‚æœæ˜¯å…¬å¼€è®¿é—®
{
  "note": {
    "id": "uuid",
    "title": "å¾®ç§¯åˆ†ç¬”è®°ç¬¬ä¸€ç« ",
    "file_type": "image",
    "file_url": "https://oss.example.com/notes/xxx.jpg",
    "thumbnail_url": "https://oss.example.com/notes/thumbnails/xxx.jpg",
    "ocr_text": "ç¬”è®°å†…å®¹...",
    "author": {
      "id": "uuid",
      "full_name": "å¼ ä¸‰"
    },
    "view_count": 100,
    "created_at": "2026-02-08T10:30:00Z"
  },
  "permissions": {
    "allow_download": true,
    "allow_merge": true
  }
}

// å¦‚æœæ˜¯å¯†ç ä¿æŠ¤
Response 401:
{
  "detail": "Password required",
  "require_password": true
}

// éœ€è¦å¯†ç éªŒè¯
POST /api/notes/share/{share_id}/authenticate
Request:
{
  "password": "password123"
}
```

#### 3. ä¸‹è½½ç¬”è®°
```
POST /api/notes/share/{share_id}/download
Response 200:
{
  "download_url": "https://oss.example.com/notes/xxx.jpg?download=true",
  "expires_at": "2026-02-08T11:30:00Z"
}
```

#### 4. åˆå¹¶ç¬”è®°åˆ°è‡ªå·±çš„ç¬”è®°åº“
```
POST /api/notes/share/{share_id}/merge
Authorization: Bearer {access_token}
Content-Type: application/json

Request:
{
  "category_id": "uuid",  // ç›®æ ‡åˆ†ç±»
  "deduplicate": true  // æ˜¯å¦å»é‡
}

Response 200:
{
  "merged_note": {
    "id": "uuid",
    "title": "å¾®ç§¯åˆ†ç¬”è®°ç¬¬ä¸€ç« ï¼ˆæ¥è‡ªå¼ ä¸‰ï¼‰",
    "created_at": "2026-02-08T11:00:00Z"
  },
  "skipped_duplicates": 2,
  "new_categories_created": 0
}
```

#### 5. æ·»åŠ åä½œè€…
```
POST /api/notes/{note_id}/collaborators
Authorization: Bearer {access_token}
Content-Type: application/json

Request:
{
  "user_ids": ["uuid1", "uuid2"],
  "permission": "edit"  // view, edit
}

Response 200:
{
  "collaborators": [
    {
      "id": "uuid1",
      "full_name": "æå››",
      "permission": "edit",
      "joined_at": "2026-02-08T11:00:00Z"
    }
  ]
}
```

#### 6. WebSocketè¿æ¥ï¼ˆå®æ—¶åä½œï¼‰
```
WS /api/notes/{note_id}/collaborate
Authorization: Bearer {access_token}

// è¿æ¥æˆåŠŸ
{
  "type": "connected",
  "note_id": "uuid",
  "collaborators": [
    {
      "id": "uuid",
      "name": "å¼ ä¸‰",
      "cursor": {"line": 10, "column": 5}
    }
  ]
}

// æ¥æ”¶å…¶ä»–ç”¨æˆ·çš„ä¿®æ”¹
{
  "type": "update",
  "user_id": "uuid",
  "user_name": "æå››",
  "operation": {
    "type": "insert",
    "position": 100,
    "text": "æ–°å¢å†…å®¹"
  }
}

// å‘é€è‡ªå·±çš„ä¿®æ”¹
{
  "type": "update",
  "operation": {
    "type": "insert",
    "position": 150,
    "text": "æˆ‘çš„ä¿®æ”¹"
  }
}
```

### ğŸ’» æŠ€æœ¯å®ç°

#### 1. åˆ†äº«é“¾æ¥ç”Ÿæˆ
```python
# app/services/share.py
import shortuuid
import qrcode
from io import BytesIO
import base64

def generate_share_id():
    """ç”ŸæˆçŸ­é“¾æ¥ID"""
    return shortuuid.uuid()[:8]

async def create_note_share(note_id: str, user_id: str, share_data: dict, db: Session):
    """åˆ›å»ºç¬”è®°åˆ†äº«"""
    note = db.query(Note).filter(Note.id == note_id, Note.user_id == user_id).first()
    if not note:
        raise HTTPException(status_code=404, detail="Note not found")

    # ç”Ÿæˆåˆ†äº«ID
    share_id = generate_share_id()

    # å¯†ç å“ˆå¸Œ
    password_hash = None
    if share_data.get("access_type") == "password":
        password_hash = hash_password(share_data["password"])

    # åˆ›å»ºåˆ†äº«è®°å½•
    share = NoteShare(
        note_id=note_id,
        user_id=user_id,
        share_id=share_id,
        access_type=share_data.get("access_type", "public"),
        password_hash=password_hash,
        allow_download=share_data.get("allow_download", True),
        allow_merge=share_data.get("allow_merge", True),
        expires_at=share_data.get("expires_at")
    )
    db.add(share)
    db.commit()
    db.refresh(share)

    # ç”ŸæˆäºŒç»´ç 
    share_url = f"{settings.FRONTEND_URL}/share/{share_id}"
    qr = qrcode.QRCode(version=1, box_size=10, border=5)
    qr.add_data(share_url)
    qr.make(fit=True)

    img = qr.make_image(fill_color="black", back_color="white")
    buffer = BytesIO()
    img.save(buffer, format="PNG")
    qr_code = base64.b64encode(buffer.getvalue()).decode("utf-8")

    return {
        **share.__dict__,
        "share_url": share_url,
        "qr_code": f"data:image/png;base64,{qr_code}"
    }
```

#### 2. æ™ºèƒ½åˆå¹¶ç®—æ³•
```python
# app/services/note_merge.py
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

async def merge_shared_note(share_id: str, user_id: str, merge_options: dict, db: Session):
    """åˆå¹¶åˆ†äº«çš„ç¬”è®°åˆ°ç”¨æˆ·ç¬”è®°åº“"""
    # 1. è·å–åˆ†äº«ç¬”è®°
    share = db.query(NoteShare).filter(NoteShare.share_id == share_id).first()
    if not share:
        raise HTTPException(status_code=404, detail="Share not found")

    shared_note = share.note

    # 2. æ£€æŸ¥æ˜¯å¦éœ€è¦å»é‡
    skipped = 0
    if merge_options.get("deduplicate", True):
        # è®¡ç®—ä¸ç”¨æˆ·ç°æœ‰ç¬”è®°çš„ç›¸ä¼¼åº¦
        user_notes = db.query(Note).filter(Note.user_id == user_id).all()

        for note in user_notes:
            similarity = calculate_note_similarity(shared_note, note)
            if similarity > 0.8:  # ç›¸ä¼¼åº¦é˜ˆå€¼
                skipped += 1
                continue

    # 3. åˆ›å»ºæ–°ç¬”è®°ï¼ˆå‰¯æœ¬ï¼‰
    new_note = Note(
        user_id=user_id,
        title=f"{shared_note.title}ï¼ˆæ¥è‡ª{share.user.full_name}ï¼‰",
        content=shared_note.content,
        file_type=shared_note.file_type,
        file_url=shared_note.file_url,
        ocr_text=shared_note.ocr_text,
        ocr_confidence=shared_note.ocr_confidence,
        embedding=shared_note.embedding,
        category_id=merge_options.get("category_id")
    )
    db.add(new_note)
    db.commit()
    db.refresh(new_note)

    # 4. æ›´æ–°ç»Ÿè®¡
    share.merge_count += 1

    return {
        "merged_note": new_note,
        "skipped_duplicates": skipped
    }

def calculate_note_similarity(note1: Note, note2: Note):
    """è®¡ç®—ä¸¤ç¯‡ç¬”è®°çš„ç›¸ä¼¼åº¦"""
    if not note1.embedding or not note2.embedding:
        return 0

    # ä½™å¼¦ç›¸ä¼¼åº¦
    vec1 = np.array(note1.embedding).reshape(1, -1)
    vec2 = np.array(note2.embedding).reshape(1, -1)

    similarity = cosine_similarity(vec1, vec2)[0][0]
    return similarity
```

#### 3. å®æ—¶åä½œï¼ˆWebSocketï¼‰
```python
# app/api/websocket.py
from fastapi import WebSocket
from typing import Dict
import json

class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, list] = {}  # note_id -> [WebSocket]

    async def connect(self, websocket: WebSocket, note_id: str):
        await websocket.accept()
        if note_id not in self.active_connections:
            self.active_connections[note_id] = []
        self.active_connections[note_id].append(websocket)

    def disconnect(self, websocket: WebSocket, note_id: str):
        self.active_connections[note_id].remove(websocket)

    async def broadcast(self, note_id: str, message: dict, exclude: WebSocket = None):
        if note_id in self.active_connections:
            for connection in self.active_connections[note_id]:
                if connection != exclude:
                    await connection.send_json(message)

manager = ConnectionManager()

@app.websocket("/api/notes/{note_id}/collaborate")
async def websocket_endpoint(websocket: WebSocket, note_id: str, token: str):
    # éªŒè¯token
    user = await get_current_user_websocket(token)

    # æ£€æŸ¥æƒé™
    note = db.query(Note).filter(Note.id == note_id).first()
    if not note or note.user_id != user.id:
        await websocket.close(code=1008, reason="Not authorized")
        return

    # è¿æ¥
    await manager.connect(websocket, note_id)

    # å‘é€å½“å‰åä½œè€…åˆ—è¡¨
    collaborators = get_active_collaborators(note_id)
    await websocket.send_json({
        "type": "connected",
        "note_id": note_id,
        "collaborators": collaborators
    })

    try:
        while True:
            # æ¥æ”¶æ¶ˆæ¯
            data = await websocket.receive_json()

            if data["type"] == "update":
                # å¹¿æ’­ç»™å…¶ä»–åä½œè€…
                await manager.broadcast(note_id, {
                    "type": "update",
                    "user_id": str(user.id),
                    "user_name": user.full_name,
                    "operation": data["operation"]
                }, exclude=websocket)

                # ä¿å­˜åˆ°æ•°æ®åº“
                await save_note_update(note_id, data["operation"], db)

            elif data["type"] == "cursor":
                # å¹¿æ’­å…‰æ ‡ä½ç½®
                await manager.broadcast(note_id, {
                    "type": "cursor",
                    "user_id": str(user.id),
                    "user_name": user.full_name,
                    "cursor": data["cursor"]
                }, exclude=websocket)

    except WebSocketDisconnect:
        manager.disconnect(websocket, note_id)
```

### âœ… éªŒæ”¶æ ‡å‡†

- [ ] **åˆ†äº«é“¾æ¥ç”Ÿæˆ**: çŸ­é“¾æ¥å”¯ä¸€ä¸”å¯è®¿é—®
- [ ] **è®¿é—®æ§åˆ¶ç”Ÿæ•ˆ**: å¯†ç ä¿æŠ¤ã€æŒ‡å®šç”¨æˆ·è®¿é—®æ­£å¸¸
- [ ] **ä¸‹è½½åŠŸèƒ½æ­£å¸¸**: å¯ä»¥ä¸‹è½½åˆ†äº«çš„ç¬”è®°
- [ ] **æ™ºèƒ½åˆå¹¶å‡†ç¡®**: å»é‡ç›¸ä¼¼åº¦è®¡ç®—æ­£ç¡®
- [ ] **å®æ—¶åä½œæµç•…**: å¤šäººåŒæ—¶ç¼–è¾‘æ— å†²çª
- [ ] **WebSocketåŒæ­¥**: ä¿®æ”¹å®æ—¶åŒæ­¥åˆ°å…¶ä»–ç”¨æˆ·

---

## #2 å­¦ä¹ æ•°æ®åˆ†æä¸å¯è§†åŒ–

**ä¼˜å…ˆçº§**: P2
**é¢„è®¡å·¥æœŸ**: 5-7å¤©
**ä¾èµ–**: ä»»åŠ¡#6ï¼ˆçŸ¥è¯†ç‚¹æé—®ï¼‰
**è´Ÿè´£è§’è‰²**: åç«¯å·¥ç¨‹å¸ˆ + å‰ç«¯å·¥ç¨‹å¸ˆ

### ğŸ“Œ ä»»åŠ¡ç›®æ ‡

å®ç°å­¦ä¹ æ•°æ®ç»Ÿè®¡ä¸å¯è§†åŒ–å±•ç¤ºï¼ŒåŒ…æ‹¬å­¦ä¹ æ—¶é•¿ã€çŸ¥è¯†ç‚¹æŒæ¡åº¦ã€å­¦ä¹ æ›²çº¿ã€ç›®æ ‡è¾¾æˆç‡ç­‰ã€‚

### ğŸ“ åŠŸèƒ½éœ€æ±‚

#### 1. å­¦ä¹ æ—¶é•¿ç»Ÿè®¡
- æ—¥/å‘¨/æœˆå­¦ä¹ æ—¶é•¿
- å­¦ä¹ æ—¶æ®µåˆ†æï¼ˆæ•ˆç‡æœ€é«˜çš„æ—¶æ®µï¼‰
- å­¦ä¹ æ—¥å†è§†å›¾

#### 2. çŸ¥è¯†ç‚¹æŒæ¡åº¦
- æ¯ä¸ªçŸ¥è¯†ç‚¹çš„æŒæ¡åº¦è¯„åˆ†ï¼ˆ0-100ï¼‰
- çƒ­åŠ›å›¾å±•ç¤º
- æŒæ¡åº¦è¶‹åŠ¿

#### 3. å­¦ä¹ æ›²çº¿
- ç­”é¢˜æ­£ç¡®ç‡è¶‹åŠ¿
- é”™é¢˜æ”¶æ•›é€Ÿåº¦
- å­¦ä¹ è¿›åº¦æ›²çº¿

#### 4. å­¦ä¹ ç›®æ ‡è¾¾æˆç‡
- è®¾å®šå­¦ä¹ ç›®æ ‡ï¼ˆæ¯æ—¥/æ¯å‘¨ï¼‰
- ç›®æ ‡å®Œæˆè¿›åº¦
- ç›®æ ‡å†å²è®°å½•

#### 5. å­¦ä¹ æŠ¥å‘Šç”Ÿæˆ
- å‘¨æŠ¥
- æœˆæŠ¥
- å¯¼å‡ºPDF

### ğŸ”Œ APIç«¯ç‚¹è®¾è®¡

#### 1. è·å–å­¦ä¹ æ¦‚è§ˆ
```
GET /api/analytics/overview?period=week
Authorization: Bearer {access_token}

Response 200:
{
  "period": "week",
  "total_study_time": 7200,  // ç§’
  "total_notes": 12,
  "total_quizzes": 8,
  "accuracy_rate": 0.75,
  "mistakes_solved": 15,
  "daily_breakdown": [
    {
      "date": "2026-02-06",
      "study_time": 1800,
      "notes_created": 3,
      "quizzes_taken": 2
    },
    {
      "date": "2026-02-07",
      "study_time": 2400,
      "notes_created": 2,
      "quizzes_taken": 3
    }
  ]
}
```

#### 2. è·å–å­¦ä¹ æ—¶é•¿
```
GET /api/analytics/study-time?start_date=2026-02-01&end_date=2026-02-08
Authorization: Bearer {access_token}

Response 200:
{
  "total_seconds": 14400,
  "average_daily": 2057,
  "hourly_breakdown": [
    {"hour": 8, "duration": 1200},
    {"hour": 9, "duration": 2400},
    {"hour": 10, "duration": 1800},
    // ...
  ],
  "best_hours": [9, 10, 14],  // å­¦ä¹ æ•ˆç‡æœ€é«˜çš„æ—¶æ®µ
  "calendar": {
    "2026-02-01": {"duration": 1200, "notes": 2},
    "2026-02-02": {"duration": 1800, "notes": 3},
    // ...
  }
}
```

#### 3. è·å–çŸ¥è¯†ç‚¹æŒæ¡åº¦
```
GET /api/analytics/mastery?mindmap_id=uuid
Authorization: Bearer {access_token}

Response 200:
{
  "mindmap_id": "uuid",
  "overall_mastery": 0.68,
  "knowledge_points": [
    {
      "id": "uuid",
      "text": "å¯¼æ•°å®šä¹‰",
      "mastery": 0.8,
      "question_count": 10,
      "correct_count": 8,
      "trend": "up"  // up, down, stable
    },
    {
      "id": "uuid",
      "text": "æ±‚å¯¼æ³•åˆ™",
      "mastery": 0.5,
      "question_count": 10,
      "correct_count": 5,
      "trend": "stable"
    }
  ],
  "heatmap_data": [
    {"x": 0, "y": 1, "value": 0.8},
    {"x": 1, "y": 2, "value": 0.5},
    // ...
  ]
}
```

#### 4. è·å–å­¦ä¹ æ›²çº¿
```
GET /api/analytics/learning-curve?period=month
Authorization: Bearer {access_token}

Response 200:
{
  "period": "month",
  "accuracy_curve": [
    {"date": "2026-02-01", "accuracy": 0.6},
    {"date": "2026-02-08", "accuracy": 0.75}
  ],
  "mistake_convergence": {
    "new_mistakes": [5, 3, 2, 1, 0],  // æ¯å‘¨æ–°é”™é¢˜æ•°
    "repeated_mistakes": [2, 1, 1, 0, 0]  // æ¯å‘¨é‡å¤é”™é¢˜æ•°
  },
  "progress_velocity": 1.5  // æ¯å‘¨æŒæ¡çŸ¥è¯†ç‚¹æ•°
}
```

#### 5. è·å–å­¦ä¹ ç›®æ ‡
```
GET /api/analytics/goals?status=active
Authorization: Bearer {access_token}

Response 200:
{
  "goals": [
    {
      "id": "uuid",
      "type": "daily",  // daily, weekly
      "target": {
        "study_time": 3600,  // ç§’
        "notes_created": 5,
        "quizzes_taken": 10
      },
      "current": {
        "study_time": 2400,
        "notes_created": 3,
        "quizzes_taken": 7
      },
      "completion_rate": 0.67,
      "due_date": "2026-02-08T23:59:59Z",
      "status": "in_progress"  // completed, in_progress, failed
    }
  ]
}
```

#### 6. è®¾ç½®å­¦ä¹ ç›®æ ‡
```
POST /api/analytics/goals
Authorization: Bearer {access_token}
Content-Type: application/json

Request:
{
  "type": "weekly",
  "target": {
    "study_time": 14400,
    "notes_created": 20,
    "quizzes_taken": 30
  },
  "start_date": "2026-02-06",
  "end_date": "2026-02-13"
}

Response 201:
{
  "id": "uuid",
  "type": "weekly",
  "target": {...},
  "status": "in_progress",
  "created_at": "2026-02-06T00:00:00Z"
}
```

#### 7. ç”Ÿæˆå­¦ä¹ æŠ¥å‘Š
```
POST /api/analytics/reports
Authorization: Bearer {access_token}
Content-Type: application/json

Request:
{
  "period": "week",  // week, month
  "format": "pdf"  // pdf, json
}

Response 202:
{
  "report_id": "uuid",
  "status": "generating",
  "estimated_time": 5
}

// å¼‚æ­¥ç”Ÿæˆï¼Œå®Œæˆåé€šè¿‡WebSocketé€šçŸ¥
```

#### 8. ä¸‹è½½å­¦ä¹ æŠ¥å‘Š
```
GET /api/analytics/reports/{report_id}/download
Authorization: Bearer {access_token}

Response 200:
Content-Type: application/pdf
Content-Disposition: attachment; filename="å­¦ä¹ æŠ¥å‘Š_2026-02-08_2026-02-15.pdf"

<binary PDF data>
```

### ğŸ’» æŠ€æœ¯å®ç°

#### 1. çŸ¥è¯†ç‚¹æŒæ¡åº¦è®¡ç®—
```python
# app/services/mastery_calculator.py

def calculate_mastery(knowledge_point_id: str, user_id: str, db: Session):
    """è®¡ç®—çŸ¥è¯†ç‚¹æŒæ¡åº¦"""
    # è·å–è¯¥çŸ¥è¯†ç‚¹æ‰€æœ‰ç­”é¢˜è®°å½•
    records = db.query(UserQuizRecord).join(QuizQuestion).filter(
        QuizQuestion.knowledge_point_id == knowledge_point_id,
        UserQuizRecord.user_id == user_id
    ).all()

    if not records:
        return 0

    # 1. æ­£ç¡®ç‡ï¼ˆæƒé‡50%ï¼‰
    accuracy = sum(r.is_correct for r in records) / len(records)

    # 2. ç­”é¢˜æ•°é‡æƒé‡ï¼ˆ30%ï¼‰
    count_weight = min(len(records), 10) / 10

    # 3. æœ€è¿‘ç­”é¢˜æƒé‡ï¼ˆ20%ï¼‰
    recent_records = sorted(records, key=lambda x: x.answered_at, reverse=True)[:5]
    recent_accuracy = sum(r.is_correct for r in recent_records) / len(recent_records) if recent_records else 0

    # ç»¼åˆè¯„åˆ†
    mastery = accuracy * 0.5 + count_weight * 0.3 + recent_accuracy * 0.2

    return round(mastery, 2)

def calculate_mastery_trend(knowledge_point_id: str, user_id: str, db: Session):
    """è®¡ç®—æŒæ¡åº¦è¶‹åŠ¿"""
    # è·å–æœ€è¿‘7å¤©çš„ç­”é¢˜è®°å½•
    seven_days_ago = datetime.utcnow() - timedelta(days=7)
    recent_records = db.query(UserQuizRecord).join(QuizQuestion).filter(
        QuizQuestion.knowledge_point_id == knowledge_point_id,
        UserQuizRecord.user_id == user_id,
        UserQuizRecord.answered_at >= seven_days_ago
    ).order_by(UserQuizRecord.answered_at).all()

    if len(recent_records) < 2:
        return "stable"

    # è®¡ç®—å‰åŠæ®µå’ŒååŠæ®µçš„æ­£ç¡®ç‡
    mid = len(recent_records) // 2
    early_accuracy = sum(r.is_correct for r in recent_records[:mid]) / mid
    late_accuracy = sum(r.is_correct for r in recent_records[mid:]) / (len(recent_records) - mid)

    # åˆ¤æ–­è¶‹åŠ¿
    if late_accuracy - early_accuracy > 0.1:
        return "up"
    elif early_accuracy - late_accuracy > 0.1:
        return "down"
    else:
        return "stable"
```

#### 2. å­¦ä¹ æ—¶æ®µæ•ˆç‡åˆ†æ
```python
# app/services/time_efficiency_analyzer.py

def analyze_study_time_efficiency(user_id: str, start_date: date, end_date: date, db: Session):
    """åˆ†æå­¦ä¹ æ—¶æ®µæ•ˆç‡"""
    # è·å–æ—¶é—´æ®µå†…çš„æ‰€æœ‰å­¦ä¹ ä¼šè¯
    sessions = db.query(StudySession).filter(
        StudySession.user_id == user_id,
        StudySession.started_at >= start_date,
        StudySession.ended_at <= end_date
    ).all()

    # æŒ‰å°æ—¶åˆ†ç»„ç»Ÿè®¡
    hourly_stats = {}
    for session in sessions:
        hour = session.started_at.hour

        if hour not in hourly_stats:
            hourly_stats[hour] = {
                "total_duration": 0,
                "total_correct": 0,
                "total_questions": 0
            }

        hourly_stats[hour]["total_duration"] += session.duration_seconds
        hourly_stats[hour]["total_correct"] += session.questions_correct
        hourly_stats[hour]["total_questions"] += session.questions_answered

    # è®¡ç®—æ¯å°æ—¶æ•ˆç‡ï¼ˆæ­£ç¡®ç‡ï¼‰
    hourly_efficiency = []
    for hour, stats in hourly_stats.items():
        if stats["total_questions"] > 0:
            accuracy = stats["total_correct"] / stats["total_questions"]
            hourly_efficiency.append({
                "hour": hour,
                "duration": stats["total_duration"],
                "accuracy": accuracy
            })

    # æ‰¾å‡ºæ•ˆç‡æœ€é«˜çš„æ—¶æ®µ
    best_hours = sorted(hourly_efficiency, key=lambda x: x["accuracy"], reverse=True)[:3]
    best_hours = [h["hour"] for h in best_hours]

    return {
        "hourly_breakdown": hourly_efficiency,
        "best_hours": best_hours
    }
```

#### 3. PDFæŠ¥å‘Šç”Ÿæˆ
```python
# app/services/report_generator.py
from reportlab.lib.pagesizes import letter, A4
from reportlab.pdfgen import canvas
from reportlab.lib.units import inch
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont

async def generate_pdf_report(user_id: str, period: str, db: Session):
    """ç”ŸæˆPDFå­¦ä¹ æŠ¥å‘Š"""
    # 1. æ”¶é›†æ•°æ®
    overview = get_analytics_overview(user_id, period, db)
    mastery = get_mastery_data(user_id, db)
    curve = get_learning_curve(user_id, period, db)

    # 2. åˆ›å»ºPDF
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)

    # 3. æ„å»ºå†…å®¹
    story = []

    # æ ‡é¢˜
    styles = getSampleStyleSheet()
    title = Paragraph(f"å­¦ä¹ æŠ¥å‘Š ({period})", styles["Title"])
    story.append(title)

    # æ¦‚è§ˆè¡¨æ ¼
    overview_data = [
        ["å­¦ä¹ æ—¶é•¿", f"{overview['total_study_time'] // 3600}å°æ—¶"],
        ["åˆ›å»ºç¬”è®°", str(overview['total_notes'])],
        ["å®Œæˆæµ‹éªŒ", str(overview['total_quizzes'])],
        ["æ­£ç¡®ç‡", f"{overview['accuracy_rate'] * 100:.1f}%"],
        ["è§£å†³é”™é¢˜", str(overview['mistakes_solved'])]
    ]
    overview_table = Table(overview_data, colWidths=[3*inch, 2*inch])
    story.append(overview_table)

    # æŒæ¡åº¦å›¾è¡¨ï¼ˆä½¿ç”¨matplotlibç”Ÿæˆå›¾ç‰‡ï¼‰
    chart_buffer = generate_mastery_chart(mastery)
    chart_img = Image(chart_buffer, 6*inch, 3*inch)
    story.append(chart_img)

    # å­¦ä¹ æ›²çº¿å›¾è¡¨
    curve_buffer = generate_learning_curve_chart(curve)
    curve_img = Image(curve_buffer, 6*inch, 3*inch)
    story.append(curve_img)

    # 4. ç”ŸæˆPDF
    doc.build(story)

    # 5. è¿”å›PDFæ•°æ®
    pdf_data = buffer.getvalue()
    return pdf_data

def generate_mastery_chart(mastery_data: dict):
    """ç”ŸæˆæŒæ¡åº¦å›¾è¡¨"""
    import matplotlib.pyplot as plt
    from io import BytesIO

    # åˆ›å»ºå›¾è¡¨
    fig, ax = plt.subplots(figsize=(8, 4))

    knowledge_points = [kp["text"] for kp in mastery_data["knowledge_points"]]
    mastery_scores = [kp["mastery"] for kp in mastery_data["knowledge_points"]]

    ax.bar(knowledge_points, mastery_scores)
    ax.set_xlabel("çŸ¥è¯†ç‚¹")
    ax.set_ylabel("æŒæ¡åº¦")
    ax.set_title("çŸ¥è¯†ç‚¹æŒæ¡åº¦")
    ax.set_ylim(0, 1)

    # ä¿å­˜åˆ°BytesIO
    buffer = BytesIO()
    plt.savefig(buffer, format="png", dpi=150, bbox_inches="tight")
    plt.close()

    buffer.seek(0)
    return buffer
```

### âœ… éªŒæ”¶æ ‡å‡†

- [ ] **å­¦ä¹ æ—¶é•¿å‡†ç¡®**: ç»Ÿè®¡æ•°æ®æ­£ç¡®
- [ ] **æŒæ¡åº¦è®¡ç®—åˆç†**: ç®—æ³•ç¬¦åˆé¢„æœŸ
- [ ] **å›¾è¡¨æ­£ç¡®æ¸²æŸ“**: EChartså›¾è¡¨æ˜¾ç¤ºæ­£å¸¸
- [ ] **çƒ­åŠ›å›¾å¯è§†åŒ–**: çŸ¥è¯†ç‚¹æŒæ¡çƒ­åŠ›å›¾æ­£ç¡®
- [ ] **æŠ¥å‘Šç”ŸæˆæˆåŠŸ**: PDFæŠ¥å‘ŠåŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯
- [ ] **æ•°æ®å®æ—¶æ›´æ–°**: ç»Ÿè®¡æ•°æ®åŠæ—¶æ›´æ–°

---

## #1 å‰ç«¯UI/UXå¼€å‘

**ä¼˜å…ˆçº§**: P1
**é¢„è®¡å·¥æœŸ**: 10-14å¤©
**ä¾èµ–**: æ‰€æœ‰åç«¯API
**è´Ÿè´£è§’è‰²**: å‰ç«¯å·¥ç¨‹å¸ˆ

### ğŸ“Œ ä»»åŠ¡ç›®æ ‡

å¼€å‘ç¾è§‚æ˜“ç”¨çš„Webå‰ç«¯ç•Œé¢ï¼Œå®ç°æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½çš„å‰ç«¯å±•ç¤ºå’Œäº¤äº’ã€‚

### ğŸ›  æŠ€æœ¯æ ˆ

#### æ ¸å¿ƒæ¡†æ¶
- **æ¡†æ¶**: Next.js 14 (App Router)
- **è¯­è¨€**: TypeScript 5+
- **æ ·å¼**: Tailwind CSS 3.4+
- **ç»„ä»¶åº“**: shadcn/ui
- **çŠ¶æ€ç®¡ç†**: Zustand
- **æ•°æ®è·å–**: React Query (TanStack Query)
- **è·¯ç”±**: Next.js App Router
- **è¡¨å•**: React Hook Form + Zod

#### UIç»„ä»¶
- **å›¾è¡¨**: ECharts / Recharts
- **è„‘å›¾å¯è§†åŒ–**: D3.js / React Flow
- **å¯Œæ–‡æœ¬ç¼–è¾‘å™¨**: Tiptap / Lexical
- **æ–‡ä»¶ä¸Šä¼ **: react-dropzone
- **ä»£ç é«˜äº®**: Shiki / Prism.js

#### å·¥å…·åº“
- **HTTPå®¢æˆ·ç«¯**: Axios
- **æ—¥æœŸå¤„ç†**: date-fns
- **å›¾æ ‡**: Lucide React
- **åŠ¨ç”»**: Framer Motion

### ğŸ“ æ ¸å¿ƒé¡µé¢

#### 1. é¦–é¡µ/Dashboard
**è·¯å¾„**: `/`

**åŠŸèƒ½**:
- å­¦ä¹ æ¦‚è§ˆå¡ç‰‡ï¼ˆå­¦ä¹ æ—¶é•¿ã€ç¬”è®°æ•°ã€æ­£ç¡®ç‡ï¼‰
- æœ€è¿‘ç¬”è®°åˆ—è¡¨
- å¾…å¤ä¹ é”™é¢˜æ•°é‡
- å­¦ä¹ æ—¥å†çƒ­åŠ›å›¾
- å¿«é€Ÿæ“ä½œæŒ‰é’®ï¼ˆä¸Šä¼ ç¬”è®°ã€å¼€å§‹æµ‹éªŒï¼‰

**ç»„ä»¶ç»“æ„**:
```tsx
// app/page.tsx
export default function DashboardPage() {
  return (
    <div className="container mx-auto p-6">
      <DashboardHeader />
      <StatsCards />
      <RecentNotes />
      <UpcomingReviews />
      <StudyCalendar />
    </div>
  )
}
```

**æ•°æ®è·å–**:
```tsx
// app/components/DashboardHeader.tsx
import { useQuery } from '@tanstack/react-query'

export function DashboardHeader() {
  const { data: overview } = useQuery({
    queryKey: ['analytics', 'overview'],
    queryFn: () => fetch('/api/analytics/overview').then(r => r.json())
  })

  return (
    <div>
      <h1>æ¬¢è¿å›æ¥ï¼Œ{user?.full_name}</h1>
      <p>æœ¬å‘¨å­¦ä¹ äº†{overview?.total_study_time}å°æ—¶</p>
    </div>
  )
}
```

#### 2. ç¬”è®°ç®¡ç†é¡µ
**è·¯å¾„**: `/notes`

**åŠŸèƒ½**:
- ç¬”è®°åˆ—è¡¨ï¼ˆç½‘æ ¼/åˆ—è¡¨è§†å›¾åˆ‡æ¢ï¼‰
- æœç´¢/ç­›é€‰ç¬”è®°
- ä¸Šä¼ ç¬”è®°æŒ‰é’®
- ç¬”è®°å¡ç‰‡ï¼ˆæ˜¾ç¤ºç¼©ç•¥å›¾ã€æ ‡é¢˜ã€æ ‡ç­¾ï¼‰
- ç¬”è®°è¯¦æƒ…é¡µ
- ç¬”è®°ç¼–è¾‘å™¨

**ç»„ä»¶ç»“æ„**:
```tsx
// app/notes/page.tsx
export default function NotesPage() {
  return (
    <div className="container mx-auto p-6">
      <NotesHeader />
      <NotesFilters />
      <NotesGrid />
      <UploadButton />
    </div>
  )
}

// app/components/NotesGrid.tsx
export function NotesGrid() {
  const { data: notes } = useQuery({
    queryKey: ['notes'],
    queryFn: () => fetch('/api/notes').then(r => r.json())
  })

  return (
    <div className="grid grid-cols-1 md:grid-cols-3 lg:grid-cols-4 gap-4">
      {notes?.map(note => (
        <NoteCard key={note.id} note={note} />
      ))}
    </div>
  )
}
```

**ç¬”è®°ä¸Šä¼ ç»„ä»¶**:
```tsx
// app/components/UploadNoteModal.tsx
import { useDropzone } from 'react-dropzone'

export function UploadNoteModal() {
  const { mutate: uploadNote } = useMutation({
    mutationFn: (file: File) => {
      const formData = new FormData()
      formData.append('file', file)
      return fetch('/api/notes/upload', {
        method: 'POST',
        body: formData
      }).then(r => r.json())
    }
  })

  const { getRootProps, getInputProps } = useDropzone({
    accept: {
      'image/*': ['.jpg', '.jpeg', '.png', '.heic'],
      'application/pdf': ['.pdf']
    },
    maxSize: 50 * 1024 * 1024, // 50MB
    onDrop: (files) => {
      files.forEach(file => uploadNote(file))
    }
  })

  return (
    <div {...getRootProps()} className="border-dashed border-2 p-8">
      <input {...getInputProps()} />
      <p>æ‹–æ‹½æ–‡ä»¶åˆ°è¿™é‡Œï¼Œæˆ–ç‚¹å‡»ä¸Šä¼ </p>
    </div>
  )
}
```

#### 3. è„‘å›¾å±•ç¤ºé¡µ
**è·¯å¾„**: `/mindmaps/[id]`

**åŠŸèƒ½**:
- äº¤äº’å¼è„‘å›¾ï¼ˆä½¿ç”¨React Flowï¼‰
- ç¼©æ”¾ã€æ‹–æ‹½
- èŠ‚ç‚¹ç‚¹å‡»å±•å¼€/æŠ˜å 
- ç¼–è¾‘æ¨¡å¼
- å¯¼å‡ºå›¾ç‰‡

**ç»„ä»¶ç»“æ„**:
```tsx
// app/mindmaps/[id]/page.tsx
'use client'

import ReactFlow, { Node, Edge } from 'reactflow'
import 'reactflow/dist/style.css'

export default function MindmapPage({ params }: { params: { id: string } }) {
  const { data: mindmap } = useQuery({
    queryKey: ['mindmap', params.id],
    queryFn: () => fetch(`/api/mindmaps/${params.id}`).then(r => r.json())
  })

  const [nodes, setNodes] = useState<Node[]>([])
  const [edges, setEdges] = useState<Edge[]>([])

  useEffect(() => {
    if (mindmap) {
      const { nodes: convertedNodes, edges: convertedEdges } =
        convertMindmapToReactFlow(mindmap.structure)
      setNodes(convertedNodes)
      setEdges(convertedEdges)
    }
  }, [mindmap])

  return (
    <div className="h-screen">
      <ReactFlow
        nodes={nodes}
        edges={edges}
        onNodesChange={onNodesChange}
        onEdgesChange={onEdgesChange}
        fitView
      >
        <Controls />
        <MiniMap />
        <Background />
      </ReactFlow>
    </div>
  )
}

function convertMindmapToReactFlow(structure: any): { nodes: Node[], edges: Edge[] } {
  const nodes: Node[] = []
  const edges: Edge[] = []

  function traverse(node: any, parentId: string | null = null, position: {x: number, y: number} = {x: 0, y: 0}) {
    const newNode: Node = {
      id: node.id,
      type: 'default',
      position,
      data: { label: node.text }
    }
    nodes.push(newNode)

    if (parentId) {
      edges.push({
        id: `${parentId}-${node.id}`,
        source: parentId,
        target: node.id
      })
    }

    // é€’å½’å¤„ç†å­èŠ‚ç‚¹
    if (node.children && node.children.length > 0) {
      const childCount = node.children.length
      node.children.forEach((child: any, index: number) => {
        const angle = (index / childCount) * 2 * Math.PI
        const radius = 200
        const childPosition = {
          x: position.x + radius * Math.cos(angle),
          y: position.y + radius * Math.sin(angle)
        }
        traverse(child, node.id, childPosition)
      })
    }
  }

  traverse(structure)
  return { nodes, edges }
}
```

#### 4. ç­”é¢˜é¡µé¢
**è·¯å¾„**: `/quizzes/[id]`

**åŠŸèƒ½**:
- é¢˜ç›®å±•ç¤ºï¼ˆæ”¯æŒé€‰æ‹©é¢˜ã€å¡«ç©ºé¢˜ã€ç®€ç­”é¢˜ï¼‰
- ç­”æ¡ˆé€‰æ‹©/è¾“å…¥
- æäº¤æŒ‰é’®
- ç­”é¢˜ç»“æœåé¦ˆ
- é”™é¢˜å®šä½æç¤º

**ç»„ä»¶ç»“æ„**:
```tsx
// app/quizzes/[id]/page.tsx
export default function QuizPage({ params }: { params: { id: string } }) {
  return (
    <div className="container mx-auto p-6 max-w-3xl">
      <QuizHeader />
      <QuestionList />
      <QuizSubmit />
    </div>
  )
}

// app/components/QuestionCard.tsx
export function QuestionCard({ question, onAnswer }) {
  const [selectedAnswer, setSelectedAnswer] = useState('')

  return (
    <div className="border rounded-lg p-6 mb-4">
      <p className="text-lg mb-4">{question.question_text}</p>

      {question.question_type === 'choice' && (
        <div className="space-y-2">
          {question.options.map((option, index) => (
            <label key={index} className="flex items-center p-3 border rounded cursor-pointer hover:bg-gray-50">
              <input
                type="radio"
                name={question.id}
                value={option}
                checked={selectedAnswer === option}
                onChange={(e) => setSelectedAnswer(e.target.value)}
                className="mr-3"
              />
              {option}
            </label>
          ))}
        </div>
      )}

      {question.question_type === 'fill_blank' && (
        <input
          type="text"
          value={selectedAnswer}
          onChange={(e) => setSelectedAnswer(e.target.value)}
          className="w-full border rounded p-3"
          placeholder="è¯·è¾“å…¥ç­”æ¡ˆ"
        />
      )}

      <button
        onClick={() => onAnswer(question.id, selectedAnswer)}
        className="mt-4 px-6 py-2 bg-blue-600 text-white rounded"
      >
        æäº¤ç­”æ¡ˆ
      </button>
    </div>
  )
}
```

#### 5. é”™é¢˜åº“é¡µ
**è·¯å¾„**: `/mistakes`

**åŠŸèƒ½**:
- é”™é¢˜åˆ—è¡¨
- ç­›é€‰/æ’åºï¼ˆæŒ‰æ ‡ç­¾ã€æ—¶é—´ã€é”™è¯¯æ¬¡æ•°ï¼‰
- é”™é¢˜è¯¦æƒ…
- å¤ä¹ æ¨¡å¼

**ç»„ä»¶ç»“æ„**:
```tsx
// app/mistakes/page.tsx
export default function MistakesPage() {
  return (
    <div className="container mx-auto p-6">
      <MistakesHeader />
      <MistakesFilters />
      <MistakesList />
    </div>
  )
}

// app/components/MistakesList.tsx
export function MistakesList() {
  const { data: mistakes } = useQuery({
    queryKey: ['mistakes'],
    queryFn: () => fetch('/api/mistakes').then(r => r.json())
  })

  return (
    <div className="space-y-4">
      {mistakes?.map(mistake => (
        <MistakeCard key={mistake.id} mistake={mistake} />
      ))}
    </div>
  )
}

// app/components/MistakeCard.tsx
export function MistakeCard({ mistake }) {
  return (
    <div className="border rounded-lg p-6">
      <div className="flex justify-between items-start mb-4">
        <h3 className="text-lg">{mistake.question_text}</h3>
        <span className="bg-red-100 text-red-800 px-2 py-1 rounded text-sm">
          é”™è¯¯ {mistake.mistake_count} æ¬¡
        </span>
      </div>

      <div className="flex gap-2 mb-4">
        {mistake.tags.map(tag => (
          <span key={tag} className="bg-gray-100 px-2 py-1 rounded text-sm">
            {tag}
          </span>
        ))}
      </div>

      <div className="flex gap-2">
        <button className="px-4 py-2 bg-blue-600 text-white rounded">
          æŸ¥çœ‹è§£æ
        </button>
        <button className="px-4 py-2 bg-green-600 text-white rounded">
          å¤ä¹ 
        </button>
      </div>

      {mistake.related_note && (
        <div className="mt-4 p-4 bg-gray-50 rounded">
          <p className="text-sm text-gray-600 mb-2">ç›¸å…³ç¬”è®°ç‰‡æ®µï¼š</p>
          <p className="text-sm">{mistake.related_note.snippet}</p>
        </div>
      )}
    </div>
  )
}
```

#### 6. æ•°æ®åˆ†æé¡µ
**è·¯å¾„**: `/analytics`

**åŠŸèƒ½**:
- å›¾è¡¨å±•ç¤ºï¼ˆEChartsï¼‰
- æ—¶é—´èŒƒå›´é€‰æ‹©
- æ•°æ®å¯¼å‡º
- å­¦ä¹ æŠ¥å‘Šç”Ÿæˆ

**ç»„ä»¶ç»“æ„**:
```tsx
// app/analytics/page.tsx
'use client'

import ReactECharts from 'echarts-for-react'

export default function AnalyticsPage() {
  const { data: studyTime } = useQuery({
    queryKey: ['analytics', 'study-time'],
    queryFn: () => fetch('/api/analytics/study-time').then(r => r.json())
  })

  const option = {
    title: { text: 'å­¦ä¹ æ—¶é•¿ç»Ÿè®¡' },
    xAxis: {
      type: 'category',
      data: studyTime?.daily_breakdown.map(d => d.date)
    },
    yAxis: { type: 'value' },
    series: [{
      data: studyTime?.daily_breakdown.map(d => d.study_time / 3600),
      type: 'bar'
    }]
  }

  return (
    <div className="container mx-auto p-6">
      <h1 className="text-2xl mb-6">å­¦ä¹ æ•°æ®åˆ†æ</h1>

      <div className="grid grid-cols-1 md:grid-cols-2 gap-6 mb-8">
        <div className="bg-white p-6 rounded-lg shadow">
          <ReactECharts option={option} />
        </div>

        <MasteryHeatmap />
      </div>

      <LearningCurve />

      <ExportButton />
    </div>
  )
}
```

#### 7. åˆ†äº«é¡µé¢
**è·¯å¾„**: `/share/[id]`

**åŠŸèƒ½**:
- å…¬å¼€ç¬”è®°å±•ç¤º
- ä¸‹è½½æŒ‰é’®
- åˆå¹¶åˆ°ç¬”è®°åº“æŒ‰é’®

**ç»„ä»¶ç»“æ„**:
```tsx
// app/share/[id]/page.tsx
export default function SharePage({ params }: { params: { id: string } }) {
  const { data: note } = useQuery({
    queryKey: ['shared-note', params.id],
    queryFn: () => fetch(`/api/notes/share/${params.id}`).then(r => r.json())
  })

  return (
    <div className="container mx-auto p-6 max-w-4xl">
      <ShareHeader note={note} />
      <NoteContent note={note} />
      <ActionButtons note={note} />
    </div>
  )
}
```

### ğŸ¨ UI/UXè¦æ±‚

#### å“åº”å¼è®¾è®¡
```tsx
// tailwind.config.js
module.exports = {
  theme: {
    screens: {
      'sm': '640px',
      'md': '768px',
      'lg': '1024px',
      'xl': '1280px',
      '2xl': '1536px'
    }
  }
}

// ä½¿ç”¨ç¤ºä¾‹
<div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
  {/* å“åº”å¼ç½‘æ ¼ */}
</div>
```

#### æš—è‰²ä¸»é¢˜
```tsx
// app/providers/ThemeProvider.tsx
'use client'

import { createContext, useContext, useState } from 'react'

const ThemeContext = createContext({})

export function ThemeProvider({ children }) {
  const [theme, setTheme] = useState('light')

  useEffect(() => {
    document.documentElement.setAttribute('data-theme', theme)
  }, [theme])

  return (
    <ThemeContext.Provider value={{ theme, setTheme }}>
      {children}
    </ThemeContext.Provider>
  )
}
```

#### åŠ¨ç”»
```tsx
// app/components/FadeIn.tsx
import { motion } from 'framer-motion'

export function FadeIn({ children }) {
  return (
    <motion.div
      initial={{ opacity: 0, y: 20 }}
      animate={{ opacity: 1, y: 0 }}
      transition={{ duration: 0.3 }}
    >
      {children}
    </motion.div>
  )
}
```

### âœ… éªŒæ”¶æ ‡å‡†

- [ ] **æ‰€æœ‰æ ¸å¿ƒé¡µé¢å®Œæˆ**: 7ä¸ªä¸»è¦é¡µé¢å…¨éƒ¨å®ç°
- [ ] **ç§»åŠ¨ç«¯é€‚é…è‰¯å¥½**: å“åº”å¼è®¾è®¡åœ¨æ‰‹æœºä¸Šæ­£å¸¸æ˜¾ç¤º
- [ ] **é¡µé¢åŠ è½½å¿«**: é¡µé¢åŠ è½½æ—¶é—´<2ç§’
- [ ] **äº¤äº’æµç•…**: æ— å¡é¡¿ï¼ŒåŠ¨ç”»æµç•…
- [ ] **Lighthouseæµ‹è¯•é€šè¿‡**: æ€§èƒ½è¯„åˆ†>90åˆ†
- [ ] **æ— éšœç¢æ ‡å‡†**: ç¬¦åˆWCAG 2.1 AAçº§
- [ ] **æµè§ˆå™¨å…¼å®¹**: æ”¯æŒChromeã€Firefoxã€Safariã€Edgeæœ€æ–°ç‰ˆ

---

## ğŸ“Š ä»»åŠ¡æ‰§è¡Œå»ºè®®

### æ‰§è¡Œé¡ºåº

**Phase 1ï¼ˆç¬¬1-2å‘¨ï¼‰: åŸºç¡€è®¾æ–½**
1. âœ… ä»»åŠ¡#9: æŠ€æœ¯æ ˆæ­å»º
2. âœ… ä»»åŠ¡#8: æ•°æ®åº“è®¾è®¡
3. âœ… ä»»åŠ¡#7: ç”¨æˆ·è®¤è¯

**Phase 2ï¼ˆç¬¬3-6å‘¨ï¼‰: æ ¸å¿ƒåŠŸèƒ½**
4. âœ… ä»»åŠ¡#10: ç¬”è®°ä¸Šä¼ OCR
5. âœ… ä»»åŠ¡#5: AIè„‘å›¾ç”Ÿæˆ
6. âœ… ä»»åŠ¡#6: çŸ¥è¯†ç‚¹æé—®
7. âœ… ä»»åŠ¡#3: é”™é¢˜åº“ç®¡ç†

**Phase 3ï¼ˆç¬¬7-10å‘¨ï¼‰: åä½œä¸æ•°æ®**
8. âœ… ä»»åŠ¡#4: åˆ†äº«åä½œ
9. âœ… ä»»åŠ¡#2: æ•°æ®åˆ†æ
10. âœ… ä»»åŠ¡#1: å‰ç«¯UI/UX

### èµ„æºåˆ†é…

**æœ€å°å›¢é˜Ÿé…ç½®**:
- 1 x å…¨æ ˆå·¥ç¨‹å¸ˆï¼ˆåç«¯+å‰ç«¯ï¼‰
- 1 x åç«¯å·¥ç¨‹å¸ˆï¼ˆAIé›†æˆï¼‰
- 1 x å‰ç«¯å·¥ç¨‹å¸ˆï¼ˆUI/UXï¼‰

**ç†æƒ³å›¢é˜Ÿé…ç½®**:
- 1 x æŠ€æœ¯è´Ÿè´£äººï¼ˆæ¶æ„è®¾è®¡ï¼‰
- 2 x åç«¯å·¥ç¨‹å¸ˆï¼ˆAPIå¼€å‘ã€AIé›†æˆï¼‰
- 2 x å‰ç«¯å·¥ç¨‹å¸ˆï¼ˆUIå¼€å‘ã€äº¤äº’ä¼˜åŒ–ï¼‰
- 1 x æµ‹è¯•å·¥ç¨‹å¸ˆï¼ˆQAï¼‰
- 1 x DevOpså·¥ç¨‹å¸ˆï¼ˆéƒ¨ç½²è¿ç»´ï¼‰

---

## ğŸ”— ç›¸å…³æ–‡æ¡£é“¾æ¥

- [[è®°å½•å­¦ä¹ è¿‡ç¨‹é¡¹ç›®]] - åŠŸèƒ½éœ€æ±‚æ–‡æ¡£
- [[å­¦ä¹ è®°å½•é¡¹ç›®å¸‚åœºå‰æ™¯åˆ†æ]] - å¸‚åœºåˆ†æ
- [[ç³»ç»Ÿæ¶æ„è®¾è®¡æ–‡æ¡£]] - æŠ€æœ¯æ¶æ„
- [[è¯¦ç»†ä»»åŠ¡æ¸…å•]] - æœ¬æ–‡æ¡£

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-02-08
**ç»´æŠ¤è€…**: study-notes-devå›¢é˜Ÿ
